usage: transworld_hd.py [-h] [--scenario SCENARIO] [--train_data TRAIN_DATA]
                        [--training_step TRAINING_STEP]
                        [--pred_step PRED_STEP] [--hid_dim HID_DIM]
                        [--n_head N_HEAD] [--n_layer N_LAYER] [--gpu GPU]
transworld_hd.py: error: unrecognized arguments: --pretrain_model_path /mnt/workspace/wangding/Desktop/TransWorldNG/experiment/bologna_clean/data/test500/out_dim_50_n_heads_4_n_layer_4_pred_step_10
2023-06-30 02:03:06,751,751,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== process HighD_highway02_50_4_4_pred_step_10  is running! ===========
2023-06-30 02:03:07,032,32,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 273, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 156, in run
    struc_dict, feat_dict, node_id_dict, scalers =  load_graph(train_data_dir, 0, training_step-1, node_id_dict)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/graph/load_hd.py", line 55, in load_graph
    scaled = pd.DataFrame(scalers['veh'].fit_transform(df[select_columns]), columns=select_columns, index=df.index)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/sklearn/utils/_set_output.py", line 142, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/sklearn/utils/_set_output.py", line 142, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/sklearn/base.py", line 848, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/sklearn/preprocessing/_data.py", line 427, in fit
    return self.partial_fit(X, y)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/sklearn/preprocessing/_data.py", line 466, in partial_fit
    X = self._validate_data(
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/sklearn/base.py", line 535, in _validate_data
    X = check_array(X, input_name="X", **check_params)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/sklearn/utils/validation.py", line 929, in check_array
    raise ValueError(
ValueError: Found array with 0 sample(s) (shape=(0, 8)) while a minimum of 1 is required by MinMaxScaler.
Empty DataFrame
Columns: [height, width, x, xAcceleration, xVelocity, y, yAcceleration, yVelocity]
Index: []
2023-06-30 02:03:34,900,900,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== process HighD_highway01_50_4_4_pred_step_10  is running! ===========
2023-06-30 02:03:35,160,160,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
      height  width       x  ...      y  yAcceleration  yVelocity
0       1.92   4.75  344.47  ...  26.07           0.07       0.05
1       1.92   4.75  345.79  ...  26.07           0.06       0.05
2       1.92   4.75  347.11  ...  26.07           0.06       0.06
3       1.92   4.75  348.42  ...  26.07           0.06       0.06
4       1.92   4.75  349.74  ...  26.07           0.06       0.06
...      ...    ...     ...  ...    ...            ...        ...
8309    2.02   4.55    4.89  ...  21.91           0.01      -0.18
8310    2.02   4.55    6.42  ...  21.90           0.01      -0.18
8311    2.02   4.55    7.98  ...  21.89           0.01      -0.18
8312    2.02   4.55    9.56  ...  21.88           0.02      -0.18
8313    2.02   4.55   11.16  ...  21.87           0.02      -0.18

[5937 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-06-30 02:03:37,689,689,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-06-30 02:03:43,303,303,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= 10_50_1 =========
2023-06-30 02:03:44,168,168,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========

  0%|          | 0/10 [00:00<?, ?it/s]2023-06-30 02:03:44,171,171,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-06-30 02:03:44,173,173,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 02:03:44,176,176,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 02:03:44,179,179,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 02:04:53,850,850,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== process HighD_highway01_50_4_4_pred_step_10  is running! ===========
2023-06-30 02:04:54,110,110,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
      height  width       x  ...      y  yAcceleration  yVelocity
0       1.92   4.75  344.47  ...  26.07           0.07       0.05
1       1.92   4.75  345.79  ...  26.07           0.06       0.05
2       1.92   4.75  347.11  ...  26.07           0.06       0.06
3       1.92   4.75  348.42  ...  26.07           0.06       0.06
4       1.92   4.75  349.74  ...  26.07           0.06       0.06
...      ...    ...     ...  ...    ...            ...        ...
8309    2.02   4.55    4.89  ...  21.91           0.01      -0.18
8310    2.02   4.55    6.42  ...  21.90           0.01      -0.18
8311    2.02   4.55    7.98  ...  21.89           0.01      -0.18
8312    2.02   4.55    9.56  ...  21.88           0.02      -0.18
8313    2.02   4.55   11.16  ...  21.87           0.02      -0.18

[5937 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-06-30 02:04:56,650,650,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-06-30 02:05:02,363,363,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= 10_50_1 =========
2023-06-30 02:05:03,299,299,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 286, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 217, in run
    encoder.load_state_dict(torch.load(encoder_path))
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1604, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for HGT:
	Unexpected key(s) in state_dict: "hetero_input_projector.linears.road.weight", "hetero_input_projector.linears.road.bias", "hetero_input_projector.linears.tlc.weight", "hetero_input_projector.linears.tlc.bias". 
	size mismatch for gnns.0.skip: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.0.linear_k.W: copying a param with shape torch.Size([4, 50, 200]) from checkpoint, the shape in current model is torch.Size([2, 50, 200]).
	size mismatch for gnns.0.linear_q.W: copying a param with shape torch.Size([4, 50, 200]) from checkpoint, the shape in current model is torch.Size([2, 50, 200]).
	size mismatch for gnns.0.linear_v.W: copying a param with shape torch.Size([4, 50, 200]) from checkpoint, the shape in current model is torch.Size([2, 50, 200]).
	size mismatch for gnns.0.linear_a.W: copying a param with shape torch.Size([4, 200, 200]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.0.relation_pri.0: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.0.relation_pri.1: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.0.relation_pri.2: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.0.relation_pri.3: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.0.relation_att.0.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_att.1.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_att.2.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_att.3.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_msg.0.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_msg.1.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_msg.2.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_msg.3.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.skip: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.1.linear_k.W: copying a param with shape torch.Size([4, 200, 200]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.1.linear_q.W: copying a param with shape torch.Size([4, 200, 200]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.1.linear_v.W: copying a param with shape torch.Size([4, 200, 200]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.1.linear_a.W: copying a param with shape torch.Size([4, 200, 200]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.1.relation_pri.0: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.1.relation_pri.1: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.1.relation_pri.2: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.1.relation_pri.3: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.1.relation_att.0.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_att.1.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_att.2.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_att.3.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_msg.0.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_msg.1.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_msg.2.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_msg.3.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.skip: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.2.linear_k.W: copying a param with shape torch.Size([4, 200, 200]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.2.linear_q.W: copying a param with shape torch.Size([4, 200, 200]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.2.linear_v.W: copying a param with shape torch.Size([4, 200, 200]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.2.linear_a.W: copying a param with shape torch.Size([4, 200, 200]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.2.relation_pri.0: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.2.relation_pri.1: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.2.relation_pri.2: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.2.relation_pri.3: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.2.relation_att.0.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_att.1.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_att.2.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_att.3.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_msg.0.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_msg.1.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_msg.2.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_msg.3.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.skip: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.3.linear_k.W: copying a param with shape torch.Size([4, 200, 200]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.3.linear_q.W: copying a param with shape torch.Size([4, 200, 200]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.3.linear_v.W: copying a param with shape torch.Size([4, 200, 200]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.3.linear_a.W: copying a param with shape torch.Size([4, 200, 200]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.3.relation_pri.0: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.3.relation_pri.1: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.3.relation_pri.2: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.3.relation_pri.3: copying a param with shape torch.Size([12]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for gnns.3.relation_att.0.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_att.1.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_att.2.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_att.3.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_msg.0.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_msg.1.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_msg.2.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_msg.3.W: copying a param with shape torch.Size([12, 50, 50]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for hetero_input_projector.linears.lane.weight: copying a param with shape torch.Size([25, 9]) from checkpoint, the shape in current model is torch.Size([25, 5]).
/mnt/workspace/wangding/Desktop/TransWorldNG/experiment/bologna_clean/data/test500/out_dim_50_n_heads_4_n_layer_4_pred_step_10/encoder.pth
2023-06-30 02:05:27,355,355,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::------------ loss is 129.44084034072026 ---------
2023-06-30 02:05:27,355,355,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 10%|█         | 1/10 [01:43<15:29, 103.30s/it]2023-06-30 02:05:27,469,469,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current ep is 1 --------
2023-06-30 02:05:27,471,471,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 02:05:27,478,478,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 02:05:27,481,481,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 02:07:13,273,273,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::------------ loss is 105.03226737234328 ---------
2023-06-30 02:07:13,274,274,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 20%|██        | 2/10 [03:29<13:58, 104.80s/it]2023-06-30 02:07:13,330,330,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current ep is 2 --------
2023-06-30 02:07:13,333,333,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 02:07:13,337,337,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 02:07:13,340,340,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 02:07:56,313,313,INFO,scenario_hangzhoutest_data_run1_dim_50_n_heads_4_n_layer_4::========== process hangzhou_run1_50_4_4_pred_step_10  is running! ===========
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 286, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 148, in run
    node_all = pd.read_csv(train_data_dir / "node_all.csv")
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/util/_decorators.py", line 331, in wrapper
    return func(*args, **kwargs)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 950, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 605, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1442, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1735, in _make_engine
    self.handles = get_handle(
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/io/common.py", line 856, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/workspace/wangding/Desktop/TransWorldNG/experiment/hangzhou/data/run1/data/node_all.csv'
usage: transworld_finetune.py [-h] [--scenario SCENARIO]
                              [--train_data TRAIN_DATA]
                              [--training_step TRAINING_STEP]
                              [--pred_step PRED_STEP] [--hid_dim HID_DIM]
                              [--n_head N_HEAD] [--n_layer N_LAYER]
                              [--gpu GPU]
transworld_finetune.py: error: unrecognized arguments: --pretrain_model_path /mnt/workspace/wangding/Desktop/TransWorldNG/experiment/bologna_clean/data/test500/out_dim_50_n_heads_4_n_layer_4_pred_step_10
2023-06-30 02:08:58,974,974,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::------------ loss is 128.8475800424152 ---------
2023-06-30 02:08:58,974,974,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 30%|███       | 3/10 [05:14<12:16, 105.22s/it]2023-06-30 02:08:59,052,52,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current ep is 3 --------
2023-06-30 02:08:59,055,55,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 02:08:59,060,60,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 02:08:59,062,62,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start training =======
usage: transworld_finetune.py [-h] [--scenario SCENARIO]
                              [--train_data TRAIN_DATA]
                              [--training_step TRAINING_STEP]
                              [--pred_step PRED_STEP] [--hid_dim HID_DIM]
                              [--n_head N_HEAD] [--n_layer N_LAYER]
                              [--gpu GPU]
transworld_finetune.py: error: unrecognized arguments: --pretrain_model_path /mnt/workspace/wangding/Desktop/TransWorldNG/experiment/bologna_clean/data/test500/out_dim_50_n_heads_4_n_layer_4_pred_step_10
2023-06-30 02:10:44,219,219,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::------------ loss is 127.89553168402777 ---------
2023-06-30 02:10:44,221,221,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 40%|████      | 4/10 [07:00<10:31, 105.24s/it]2023-06-30 02:10:44,312,312,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current ep is 4 --------
2023-06-30 02:10:44,314,314,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 02:10:44,320,320,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 02:10:44,322,322,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 02:12:29,360,360,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::------------ loss is 124.92154900630314 ---------
2023-06-30 02:12:29,363,363,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 50%|█████     | 5/10 [08:45<08:46, 105.21s/it]2023-06-30 02:12:29,484,484,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current ep is 5 --------
2023-06-30 02:12:29,486,486,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 02:12:29,492,492,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 02:12:29,497,497,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 02:14:15,253,253,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::------------ loss is 125.24246499035095 ---------
2023-06-30 02:14:15,253,253,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 60%|██████    | 6/10 [10:31<07:01, 105.44s/it]2023-06-30 02:14:15,362,362,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current ep is 6 --------
2023-06-30 02:14:15,364,364,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 02:14:15,370,370,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 02:14:15,373,373,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 02:16:01,221,221,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::------------ loss is 132.7374807434612 ---------
2023-06-30 02:16:01,222,222,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 70%|███████   | 7/10 [12:17<05:16, 105.62s/it]2023-06-30 02:16:01,347,347,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current ep is 7 --------
2023-06-30 02:16:01,350,350,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 02:16:01,356,356,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 02:16:01,359,359,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 02:17:47,666,666,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::------------ loss is 124.97681518024868 ---------
2023-06-30 02:17:47,666,666,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 80%|████████  | 8/10 [14:03<03:31, 105.87s/it]2023-06-30 02:17:47,747,747,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current ep is 8 --------
2023-06-30 02:17:47,750,750,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 02:17:47,758,758,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 02:17:47,762,762,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 02:19:33,870,870,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::------------ loss is 132.80578233506944 ---------
2023-06-30 02:19:33,871,871,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 90%|█████████ | 9/10 [15:49<01:45, 105.97s/it]2023-06-30 02:19:33,955,955,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current ep is 9 --------
2023-06-30 02:19:33,957,957,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 02:19:33,961,961,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 02:19:33,965,965,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 02:21:19,560,560,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::------------ loss is 128.88566465391054 ---------
2023-06-30 02:21:19,560,560,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished training ==========

100%|██████████| 10/10 [17:35<00:00, 105.89s/it]
100%|██████████| 10/10 [17:35<00:00, 105.55s/it]
2023-06-30 02:21:19,759,759,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current is (10, 1010) --------
2023-06-30 02:21:19,759,759,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size50=======

0it [00:00, ?it/s]
1it [00:03,  3.20s/it]
1it [00:03,  3.24s/it]
2023-06-30 02:21:23,357,357,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
      height  width       x  ...      y  yAcceleration  yVelocity
0       1.92   4.75  344.47  ...  26.07           0.07       0.05
1       1.92   4.75  345.79  ...  26.07           0.06       0.05
2       1.92   4.75  347.11  ...  26.07           0.06       0.06
3       1.92   4.75  348.42  ...  26.07           0.06       0.06
4       1.92   4.75  349.74  ...  26.07           0.06       0.06
...      ...    ...     ...  ...    ...            ...        ...
8559    1.92   4.95  403.12  ...  13.45           0.01      -0.09
8560    1.92   4.95  401.79  ...  13.44           0.02      -0.09
8561    1.92   4.95  400.45  ...  13.44           0.02      -0.09
8844    2.50  16.47  393.14  ...   9.10           0.01      -0.18
8845    2.50  16.47  392.32  ...   9.09           0.02      -0.17

[6109 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-06-30 02:21:32,217,217,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current is (20, 1020) --------
2023-06-30 02:21:32,221,221,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size50=======

0it [00:00, ?it/s]
1it [00:03,  3.32s/it]
1it [00:03,  3.37s/it]
2023-06-30 02:21:35,986,986,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
      height  width       x  ...      y  yAcceleration  yVelocity
0       1.92   4.75  344.47  ...  26.07           0.07       0.05
1       1.92   4.75  345.79  ...  26.07           0.06       0.05
2       1.92   4.75  347.11  ...  26.07           0.06       0.06
3       1.92   4.75  348.42  ...  26.07           0.06       0.06
4       1.92   4.75  349.74  ...  26.07           0.06       0.06
...      ...    ...     ...  ...    ...            ...        ...
8854    2.50  16.47  384.28  ...   9.03           0.07      -0.12
8855    2.50  16.47  383.37  ...   9.03           0.08      -0.12
9299    1.92   4.75    4.82  ...  22.31           0.00      -0.18
9300    1.92   4.75    6.26  ...  22.30           0.01      -0.18
9301    1.92   4.75    7.75  ...  22.30           0.01      -0.18

[6274 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-06-30 02:21:45,232,232,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current is (30, 1030) --------
2023-06-30 02:21:45,233,233,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size50=======

0it [00:00, ?it/s]
1it [00:03,  3.38s/it]
1it [00:03,  3.42s/it]
2023-06-30 02:21:49,062,62,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
      height  width       x  ...      y  yAcceleration  yVelocity
0       1.92   4.75  344.47  ...  26.07           0.07       0.05
1       1.92   4.75  345.79  ...  26.07           0.06       0.05
2       1.92   4.75  347.11  ...  26.07           0.06       0.06
3       1.92   4.75  348.42  ...  26.07           0.06       0.06
4       1.92   4.75  349.74  ...  26.07           0.06       0.06
...      ...    ...     ...  ...    ...            ...        ...
9309    1.92   4.75   20.30  ...  22.24           0.04      -0.17
9310    1.92   4.75   21.89  ...  22.23           0.04      -0.17
9311    1.92   4.75   23.48  ...  22.22           0.05      -0.17
9550    1.92   4.55  404.75  ...  13.37          -0.01       0.17
9551    1.92   4.55  403.52  ...  13.38          -0.01       0.17

[6446 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-06-30 02:21:58,241,241,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current is (40, 1040) --------
2023-06-30 02:21:58,244,244,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size50=======

0it [00:00, ?it/s]
1it [00:03,  3.62s/it]
1it [00:03,  3.67s/it]
2023-06-30 02:22:02,345,345,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
      height  width       x  ...      y  yAcceleration  yVelocity
0       1.92   4.75  344.47  ...  26.07           0.07       0.05
1       1.92   4.75  345.79  ...  26.07           0.06       0.05
2       1.92   4.75  347.11  ...  26.07           0.06       0.06
3       1.92   4.75  348.42  ...  26.07           0.06       0.06
4       1.92   4.75  349.74  ...  26.07           0.06       0.06
...      ...    ...     ...  ...    ...            ...        ...
9557    1.92   4.55  395.67  ...  13.41          -0.04       0.14
9558    1.92   4.55  394.33  ...  13.41          -0.05       0.13
9559    1.92   4.55  392.98  ...  13.41          -0.05       0.13
9560    1.92   4.55  391.64  ...  13.42          -0.05       0.13
9561    1.92   4.55  390.28  ...  13.42          -0.06       0.12

[6626 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-06-30 02:22:12,247,247,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current is (50, 1050) --------
2023-06-30 02:22:12,249,249,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size50=======

0it [00:00, ?it/s]
1it [00:03,  3.77s/it]
1it [00:03,  3.82s/it]
2023-06-30 02:22:16,511,511,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
      height  width       x  ...      y  yAcceleration  yVelocity
0       1.92   4.75  344.47  ...  26.07           0.07       0.05
1       1.92   4.75  345.79  ...  26.07           0.06       0.05
2       1.92   4.75  347.11  ...  26.07           0.06       0.06
3       1.92   4.75  348.42  ...  26.07           0.06       0.06
4       1.92   4.75  349.74  ...  26.07           0.06       0.06
...      ...    ...     ...  ...    ...            ...        ...
9567    1.92   4.55  382.11  ...  13.44          -0.07       0.10
9568    1.92   4.55  380.74  ...  13.45          -0.07       0.09
9569    1.92   4.55  379.38  ...  13.45          -0.07       0.09
9570    1.92   4.55  378.02  ...  13.45          -0.07       0.09
9571    1.92   4.55  376.66  ...  13.46          -0.07       0.08

[6806 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-06-30 02:22:26,410,410,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current is (60, 1060) --------
2023-06-30 02:22:26,414,414,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size50=======

0it [00:00, ?it/s]
1it [00:03,  3.84s/it]
1it [00:03,  3.89s/it]
2023-06-30 02:22:30,892,892,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
      height  width       x  ...      y  yAcceleration  yVelocity
0       1.92   4.75  344.47  ...  26.07           0.07       0.05
1       1.92   4.75  345.79  ...  26.07           0.06       0.05
2       1.92   4.75  347.11  ...  26.07           0.06       0.06
3       1.92   4.75  348.42  ...  26.07           0.06       0.06
4       1.92   4.75  349.74  ...  26.07           0.06       0.06
...      ...    ...     ...  ...    ...            ...        ...
9577    1.92   4.55  368.52  ...  13.47          -0.07       0.06
9578    1.92   4.55  367.15  ...  13.48          -0.07       0.05
9579    1.92   4.55  365.79  ...  13.48          -0.07       0.05
9580    1.92   4.55  364.43  ...  13.48          -0.07       0.05
9581    1.92   4.55  363.07  ...  13.48          -0.07       0.04

[6986 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-06-30 02:22:41,032,32,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current is (70, 1070) --------
2023-06-30 02:22:41,035,35,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size50=======

0it [00:00, ?it/s]
1it [00:04,  4.14s/it]
1it [00:04,  4.19s/it]
2023-06-30 02:22:45,690,690,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
      height  width       x  ...      y  yAcceleration  yVelocity
0       1.92   4.75  344.47  ...  26.07           0.07       0.05
1       1.92   4.75  345.79  ...  26.07           0.06       0.05
2       1.92   4.75  347.11  ...  26.07           0.06       0.06
3       1.92   4.75  348.42  ...  26.07           0.06       0.06
4       1.92   4.75  349.74  ...  26.07           0.06       0.06
...      ...    ...     ...  ...    ...            ...        ...
9587    1.92   4.55  354.92  ...  13.49          -0.06       0.03
9588    1.92   4.55  353.56  ...  13.49          -0.06       0.02
9589    1.92   4.55  352.20  ...  13.49          -0.06       0.02
9590    1.92   4.55  350.84  ...  13.49          -0.06       0.02
9591    1.92   4.55  349.47  ...  13.49          -0.06       0.01

[7166 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-06-30 02:22:56,156,156,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current is (80, 1080) --------
2023-06-30 02:22:56,158,158,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size50=======

0it [00:00, ?it/s]
1it [00:04,  4.08s/it]
1it [00:04,  4.13s/it]
2023-06-30 02:23:00,742,742,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
       height  width       x  ...      y  yAcceleration  yVelocity
0        1.92   4.75  344.47  ...  26.07           0.07       0.05
1        1.92   4.75  345.79  ...  26.07           0.06       0.05
2        1.92   4.75  347.11  ...  26.07           0.06       0.06
3        1.92   4.75  348.42  ...  26.07           0.06       0.06
4        1.92   4.75  349.74  ...  26.07           0.06       0.06
...       ...    ...     ...  ...    ...            ...        ...
10127    2.32   5.96    6.41  ...  25.93           0.03      -0.15
10128    2.32   5.96    7.48  ...  25.92           0.04      -0.14
10129    2.32   5.96    8.56  ...  25.92           0.04      -0.14
10130    2.32   5.96    9.64  ...  25.91           0.04      -0.13
10131    2.32   5.96   10.73  ...  25.91           0.05      -0.12

[7363 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-06-30 02:23:11,474,474,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current is (90, 1090) --------
2023-06-30 02:23:11,476,476,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size50=======

0it [00:00, ?it/s]
1it [00:04,  4.34s/it]
1it [00:04,  4.39s/it]
2023-06-30 02:23:16,382,382,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
       height  width       x  ...      y  yAcceleration  yVelocity
0        1.92   4.75  344.47  ...  26.07           0.07       0.05
1        1.92   4.75  345.79  ...  26.07           0.06       0.05
2        1.92   4.75  347.11  ...  26.07           0.06       0.06
3        1.92   4.75  348.42  ...  26.07           0.06       0.06
4        1.92   4.75  349.74  ...  26.07           0.06       0.06
...       ...    ...     ...  ...    ...            ...        ...
10501    1.92   4.35  398.85  ...  13.46           0.02       0.02
10502    1.92   4.35  397.38  ...  13.46           0.02       0.03
10503    1.92   4.35  395.91  ...  13.46           0.02       0.03
10504    1.92   4.35  394.43  ...  13.46           0.02       0.03
10505    1.92   4.35  392.95  ...  13.46           0.02       0.04

[7563 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-06-30 02:23:27,271,271,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::--------- current is (100, 1100) --------
2023-06-30 02:23:27,273,273,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size50=======

0it [00:00, ?it/s]
1it [00:04,  4.33s/it]
1it [00:04,  4.38s/it]
2023-06-30 02:23:32,250,250,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
       height  width       x  ...      y  yAcceleration  yVelocity
0        1.92   4.75  344.47  ...  26.07           0.07       0.05
1        1.92   4.75  345.79  ...  26.07           0.06       0.05
2        1.92   4.75  347.11  ...  26.07           0.06       0.06
3        1.92   4.75  348.42  ...  26.07           0.06       0.06
4        1.92   4.75  349.74  ...  26.07           0.06       0.06
...       ...    ...     ...  ...    ...            ...        ...
10511    1.92   4.35  384.04  ...  13.48           0.01       0.05
10512    1.92   4.35  382.55  ...  13.48           0.01       0.06
10513    1.92   4.35  381.06  ...  13.49           0.01       0.06
10514    1.92   4.35  379.57  ...  13.49           0.01       0.06
10515    1.92   4.35  378.09  ...  13.49           0.01       0.06

[7753 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-06-30 02:23:43,477,477,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== time_diff is : 1199.307658 ==========
2023-06-30 02:23:43,479,479,INFO,scenario_HighDtest_data_highway01_dim_50_n_heads_4_n_layer_4::========== Exp has finished! ==========
2023-06-30 03:17:46,038,38,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== process hangzhou_test500_50_4_4_pred_step_10  is running! ===========
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 269, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 137, in run
    node_all = pd.read_csv(train_data_dir / "node_all.csv")
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/util/_decorators.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/util/_decorators.py", line 331, in wrapper
    return func(*args, **kwargs)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 950, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 605, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1442, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1735, in _make_engine
    self.handles = get_handle(
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/pandas/io/common.py", line 856, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/workspace/wangding/Desktop/TransWorldNG/experiment/hangzhou/data/test500/train_data/node_all.csv'
2023-06-30 06:18:10,267,267,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== process hangzhou_test500_50_4_4_pred_step_10  is running! ===========
2023-06-30 06:18:17,476,476,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
usage: transworld_finetune.py [-h] [--scenario SCENARIO]
                              [--train_data TRAIN_DATA]
                              [--training_step TRAINING_STEP]
                              [--pred_step PRED_STEP] [--hid_dim HID_DIM]
                              [--n_head N_HEAD] [--n_layer N_LAYER]
                              [--gpu GPU]
transworld_finetune.py: error: unrecognized arguments: --pretrain_model_path /mnt/workspace/wangding/Desktop/TransWorldNG/experiment/bologna_clean/data/test500/out_dim_50_n_heads_4_n_layer_4_pred_step_10
2023-06-30 06:19:02,347,347,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-06-30 06:20:14,201,201,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= 100_40_10 =========
2023-06-30 06:20:15,127,127,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========

  0%|          | 0/100 [00:00<?, ?it/s]2023-06-30 06:20:15,134,134,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-06-30 06:20:15,136,136,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 06:20:15,140,140,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 06:20:15,143,143,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).
 Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 244, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/multiprocessing/reductions.py", line 358, in reduce_storage
    fd, size = storage._share_fd_cpu_()
RuntimeError: unable to write to file </torch_237692_2952330988_67>: No space left on device (28)

  0%|          | 0/100 [00:28<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 237543) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 269, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 218, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 40, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader): 
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1325, in _get_data
    success, data = self._try_get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1176, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 237543) exited unexpectedly
2023-06-30 06:22:51,509,509,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== process hangzhou_test500_50_4_4_pred_step_10  is running! ===========
2023-06-30 06:22:58,743,743,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
2023-06-30 06:23:42,795,795,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-06-30 06:24:54,906,906,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= 100_40_10 =========
2023-06-30 06:24:55,883,883,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========

  0%|          | 0/100 [00:00<?, ?it/s]2023-06-30 06:24:55,886,886,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-06-30 06:24:55,888,888,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 06:24:55,892,892,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 06:24:55,895,895,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
usage: transworld_finetune.py [-h] [--scenario SCENARIO]
                              [--train_data TRAIN_DATA]
                              [--training_step TRAINING_STEP]
                              [--pred_step PRED_STEP] [--hid_dim HID_DIM]
                              [--n_head N_HEAD] [--n_layer N_LAYER]
                              [--gpu GPU]
transworld_finetune.py: error: unrecognized arguments: --pretrain_model_path /mnt/workspace/wangding/Desktop/TransWorldNG/experiment/bologna_clean/data/test500/out_dim_50_n_heads_4_n_layer_4_pred_step_10
ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).
 
  0%|          | 0/100 [00:30<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 240504) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 269, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 218, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 40, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader): 
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1325, in _get_data
    success, data = self._try_get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1176, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 240504) exited unexpectedly
usage: transworld_finetune.py [-h] [--scenario SCENARIO]
                              [--train_data TRAIN_DATA]
                              [--training_step TRAINING_STEP]
                              [--pred_step PRED_STEP] [--hid_dim HID_DIM]
                              [--n_head N_HEAD] [--n_layer N_LAYER]
                              [--gpu GPU]
transworld_finetune.py: error: unrecognized arguments: --pretrain_model_path /mnt/workspace/wangding/Desktop/TransWorldNG/experiment/bologna_clean/data/test500/out_dim_50_n_heads_4_n_layer_4_pred_step_10
2023-06-30 06:33:17,589,589,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== process hangzhou_test500_50_4_4_pred_step_10  is running! ===========
2023-06-30 06:33:24,784,784,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
2023-06-30 06:36:04,656,656,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== process hangzhou_test500_50_4_4_pred_step_10  is running! ===========
2023-06-30 06:36:17,287,287,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
2023-06-30 06:37:34,227,227,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-06-30 06:39:58,327,327,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= 100_40_10 =========
2023-06-30 06:39:59,565,565,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========

  0%|          | 0/100 [00:00<?, ?it/s]2023-06-30 06:39:59,569,569,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-06-30 06:39:59,572,572,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 06:39:59,576,576,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 06:39:59,579,579,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 244, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/multiprocessing/reductions.py", line 358, in reduce_storage
    fd, size = storage._share_fd_cpu_()
RuntimeError: unable to write to file </torch_244066_3513131544_74>: No space left on device (28)
ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).
 
  0%|          | 0/100 [00:31<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).
   File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 244067) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 269, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 218, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 40, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader): 
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1325, in _get_data
    success, data = self._try_get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1176, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 244067) exited unexpectedly
2023-06-30 06:40:51,218,218,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== process hangzhou_test500_50_4_4_pred_step_10  is running! ===========
2023-06-30 06:40:58,358,358,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
2023-06-30 06:41:00,026,26,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-06-30 06:41:42,465,465,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-06-30 06:42:54,715,715,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= 100_40_10 =========
2023-06-30 06:42:55,833,833,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========

  0%|          | 0/100 [00:00<?, ?it/s]2023-06-30 06:42:55,836,836,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-06-30 06:42:55,837,837,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 06:42:55,848,848,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 06:42:55,849,849,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 244, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/multiprocessing/reductions.py", line 358, in reduce_storage
    fd, size = storage._share_fd_cpu_()
RuntimeError: unable to write to file </torch_246959_4268388998_173>: No space left on device (28)
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 244, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/multiprocessing/reductions.py", line 358, in reduce_storage
    fd, size = storage._share_fd_cpu_()
RuntimeError: unable to write to file </torch_247088_649923017_0>: No space left on device (28)
ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).
 
  0%|          | 0/100 [00:30<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 246960) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 269, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 218, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 40, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader): 
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1325, in _get_data
    success, data = self._try_get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1176, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 246960) exited unexpectedly
2023-06-30 06:43:51,823,823,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== process hangzhou_test500_50_4_4_pred_step_10  is running! ===========
2023-06-30 06:43:59,058,58,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
2023-06-30 06:44:43,028,28,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-06-30 06:45:54,803,803,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= 100_40_10 =========
2023-06-30 06:45:55,917,917,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========

  0%|          | 0/100 [00:00<?, ?it/s]2023-06-30 06:45:55,919,919,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-06-30 06:45:55,920,920,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 06:45:55,924,924,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 06:45:55,927,927,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).
 
  0%|          | 0/100 [00:27<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 249596) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 269, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 218, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 40, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader): 
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1325, in _get_data
    success, data = self._try_get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1176, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 249596) exited unexpectedly
2023-06-30 06:46:41,975,975,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== process hangzhou_test500_50_4_4_pred_step_10  is running! ===========
2023-06-30 06:46:49,187,187,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
2023-06-30 06:47:33,083,83,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-06-30 06:48:45,233,233,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= 100_4_1 =========
2023-06-30 06:48:46,233,233,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========

  0%|          | 0/100 [00:00<?, ?it/s]2023-06-30 06:48:46,235,235,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-06-30 06:48:46,237,237,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 06:48:46,240,240,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 06:48:46,243,243,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 06:53:32,425,425,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.679693417115645 ---------
2023-06-30 06:53:32,425,425,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  1%|          | 1/100 [04:46<7:52:44, 286.51s/it]2023-06-30 06:53:32,744,744,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 1 --------
2023-06-30 06:53:32,746,746,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 06:53:32,749,749,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 06:53:32,752,752,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 06:57:58,525,525,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.222850874066353 ---------
2023-06-30 06:57:58,526,526,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  2%|▏         | 2/100 [09:12<7:28:18, 274.48s/it]2023-06-30 06:57:58,798,798,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 2 --------
2023-06-30 06:57:58,799,799,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 06:57:58,803,803,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 06:57:58,805,805,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:02:54,340,340,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.35761557654901 ---------
2023-06-30 07:02:54,341,341,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  3%|▎         | 3/100 [14:08<7:39:33, 284.26s/it]2023-06-30 07:02:54,707,707,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 3 --------
2023-06-30 07:02:54,709,709,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:02:54,713,713,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:02:54,716,716,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:07:38,666,666,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2329641580581665 ---------
2023-06-30 07:07:38,666,666,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  4%|▍         | 4/100 [18:52<7:34:47, 284.24s/it]2023-06-30 07:07:38,922,922,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 4 --------
2023-06-30 07:07:38,927,927,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:07:38,932,932,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:07:38,936,936,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:12:15,800,800,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.24148096347397 ---------
2023-06-30 07:12:15,803,803,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  5%|▌         | 5/100 [23:29<7:25:57, 281.66s/it]2023-06-30 07:12:15,994,994,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 5 --------
2023-06-30 07:12:15,996,996,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:12:15,997,997,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:12:16,001,1,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:17:02,166,166,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2529068209908227 ---------
2023-06-30 07:17:02,167,167,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  6%|▌         | 6/100 [28:16<7:23:48, 283.29s/it]2023-06-30 07:17:02,442,442,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 6 --------
2023-06-30 07:17:02,445,445,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:17:02,452,452,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:17:02,456,456,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:21:53,769,769,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2811811197210443 ---------
2023-06-30 07:21:53,770,770,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  7%|▋         | 7/100 [33:07<7:23:21, 286.03s/it]2023-06-30 07:21:54,130,130,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 7 --------
2023-06-30 07:21:54,132,132,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:21:54,136,136,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:21:54,141,141,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:26:39,675,675,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.199720011685382 ---------
2023-06-30 07:26:39,676,676,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  8%|▊         | 8/100 [37:53<7:18:29, 285.97s/it]2023-06-30 07:26:39,959,959,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 8 --------
2023-06-30 07:26:39,961,961,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:26:39,966,966,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:26:39,969,969,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:31:03,110,110,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.191297314383767 ---------
2023-06-30 07:31:03,110,110,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  9%|▉         | 9/100 [42:17<7:03:02, 278.92s/it]2023-06-30 07:31:03,392,392,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 9 --------
2023-06-30 07:31:03,395,395,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:31:03,401,401,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:31:03,406,406,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:35:51,205,205,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.234148681841113 ---------
2023-06-30 07:35:51,206,206,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 10%|█         | 10/100 [47:05<7:02:37, 281.75s/it]2023-06-30 07:35:51,474,474,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 10 --------
2023-06-30 07:35:51,478,478,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:35:51,484,484,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:35:51,489,489,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:40:38,150,150,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1919589178128676 ---------
2023-06-30 07:40:38,151,151,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 11%|█         | 11/100 [51:52<7:00:16, 283.33s/it]2023-06-30 07:40:38,381,381,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 11 --------
2023-06-30 07:40:38,384,384,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:40:38,389,389,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:40:38,393,393,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:45:15,186,186,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.0572896979071875 ---------
2023-06-30 07:45:15,187,187,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 12%|█▏        | 12/100 [56:29<6:52:45, 281.43s/it]2023-06-30 07:45:15,465,465,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 12 --------
2023-06-30 07:45:15,468,468,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:45:15,475,475,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:45:15,480,480,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:49:54,181,181,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.123207976872271 ---------
2023-06-30 07:49:54,182,182,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 13%|█▎        | 13/100 [1:01:08<6:47:00, 280.69s/it]2023-06-30 07:49:54,470,470,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 13 --------
2023-06-30 07:49:54,473,473,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:49:54,479,479,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:49:54,487,487,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:51:15,038,38,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= 100_200_10 =========
2023-06-30 07:51:16,430,430,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
/mnt/workspace/wangding/Desktop/TransWorldNG/experiment/bologna_clean/data/test500/out_dim_50_n_heads_4_n_layer_4_pred_step_10/encoder.pth
========== Finish load preTrain model ==========

  0%|          | 0/100 [00:00<?, ?it/s]2023-06-30 07:51:16,598,598,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-06-30 07:51:16,601,601,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:51:16,606,606,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:51:16,608,608,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:54:38,154,154,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9762691110372543 ---------
2023-06-30 07:54:38,155,155,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 14%|█▍        | 14/100 [1:05:52<6:43:46, 281.70s/it]2023-06-30 07:54:38,487,487,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 14 --------
2023-06-30 07:54:38,489,489,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:54:38,496,496,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:54:38,501,501,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 07:59:20,332,332,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.3056945518844505 ---------
2023-06-30 07:59:20,332,332,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 15%|█▌        | 15/100 [1:10:34<6:39:16, 281.84s/it]2023-06-30 07:59:20,646,646,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 15 --------
2023-06-30 07:59:20,649,649,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 07:59:20,653,653,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 07:59:20,657,657,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 08:04:01,665,665,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1137907762419093 ---------
2023-06-30 08:04:01,666,666,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 16%|█▌        | 16/100 [1:15:15<6:34:21, 281.69s/it]2023-06-30 08:04:01,992,992,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 16 --------
2023-06-30 08:04:01,994,994,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 08:04:01,998,998,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 08:04:02,001,1,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 08:08:50,045,45,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2035754451697525 ---------
2023-06-30 08:08:50,046,46,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 17%|█▋        | 17/100 [1:20:04<6:32:24, 283.67s/it]2023-06-30 08:08:50,269,269,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 17 --------
2023-06-30 08:08:50,271,271,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 08:08:50,275,275,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 08:08:50,278,278,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 08:13:38,294,294,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.177201720801267 ---------
2023-06-30 08:13:38,295,295,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 18%|█▊        | 18/100 [1:24:52<6:29:35, 285.07s/it]2023-06-30 08:13:38,595,595,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 18 --------
2023-06-30 08:13:38,597,597,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 08:13:38,601,601,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 08:13:38,605,605,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 08:18:10,387,387,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.254690620032224 ---------
2023-06-30 08:18:10,388,388,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 19%|█▉        | 19/100 [1:29:24<6:19:32, 281.15s/it]2023-06-30 08:18:10,605,605,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 19 --------
2023-06-30 08:18:10,607,607,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 08:18:10,610,610,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 08:18:10,614,614,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 08:22:58,127,127,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2780986536632883 ---------
2023-06-30 08:22:58,127,127,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 20%|██        | 20/100 [1:34:12<6:17:30, 283.13s/it]2023-06-30 08:22:58,352,352,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 20 --------
2023-06-30 08:22:58,354,354,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 08:22:58,358,358,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 08:22:58,360,360,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 08:27:48,556,556,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.136120433834466 ---------
2023-06-30 08:27:48,556,556,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 21%|██        | 21/100 [1:39:02<6:15:40, 285.33s/it]2023-06-30 08:27:48,806,806,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 21 --------
2023-06-30 08:27:48,808,808,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 08:27:48,812,812,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 08:27:48,820,820,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 08:32:31,697,697,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2457919771021064 ---------
2023-06-30 08:32:31,698,698,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 22%|██▏       | 22/100 [1:43:45<6:10:05, 284.68s/it]2023-06-30 08:32:31,989,989,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 22 --------
2023-06-30 08:32:31,991,991,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 08:32:31,995,995,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 08:32:31,998,998,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).
 
  0%|          | 0/100 [41:20<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 259498) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_finetune.py", line 280, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_finetune.py", line 228, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_finetune.py", line 40, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader): 
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1325, in _get_data
    success, data = self._try_get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1176, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 259498) exited unexpectedly
2023-06-30 08:37:20,551,551,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.133869519118558 ---------
2023-06-30 08:37:20,554,554,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 23%|██▎       | 23/100 [1:48:34<6:06:56, 285.93s/it]2023-06-30 08:37:20,827,827,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 23 --------
2023-06-30 08:37:20,830,830,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 08:37:20,834,834,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 08:37:20,838,838,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 08:42:00,568,568,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.278852494772185 ---------
2023-06-30 08:42:00,570,570,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 24%|██▍       | 24/100 [1:53:14<5:59:54, 284.14s/it]2023-06-30 08:42:00,788,788,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 24 --------
2023-06-30 08:42:00,790,790,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 08:42:00,795,795,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 08:42:00,799,799,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 08:46:26,420,420,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9359573491595008 ---------
2023-06-30 08:46:26,421,421,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 25%|██▌       | 25/100 [1:57:40<5:48:17, 278.64s/it]2023-06-30 08:46:26,595,595,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 25 --------
2023-06-30 08:46:26,597,597,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 08:46:26,601,601,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 08:46:26,604,604,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 08:50:56,715,715,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.8274509855969385 ---------
2023-06-30 08:50:56,716,716,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 26%|██▌       | 26/100 [2:02:10<5:40:36, 276.16s/it]2023-06-30 08:50:56,982,982,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 26 --------
2023-06-30 08:50:56,983,983,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 08:50:56,987,987,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 08:50:56,991,991,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 08:55:36,252,252,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2169201661917297 ---------
2023-06-30 08:55:36,256,256,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 27%|██▋       | 27/100 [2:06:50<5:37:13, 277.17s/it]2023-06-30 08:55:36,515,515,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 27 --------
2023-06-30 08:55:36,517,517,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 08:55:36,522,522,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 08:55:36,527,527,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 09:00:10,300,300,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1561210373924538 ---------
2023-06-30 09:00:10,301,301,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 28%|██▊       | 28/100 [2:11:24<5:31:27, 276.22s/it]2023-06-30 09:00:10,493,493,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 28 --------
2023-06-30 09:00:10,495,495,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 09:00:10,500,500,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 09:00:10,503,503,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 09:04:49,854,854,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1641839007762345 ---------
2023-06-30 09:04:49,855,855,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 29%|██▉       | 29/100 [2:16:03<5:28:03, 277.23s/it]2023-06-30 09:04:50,080,80,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 29 --------
2023-06-30 09:04:50,083,83,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 09:04:50,087,87,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 09:04:50,090,90,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 09:09:34,087,87,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.212802724023773 ---------
2023-06-30 09:09:34,087,87,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 30%|███       | 30/100 [2:20:48<5:25:54, 279.35s/it]2023-06-30 09:09:34,371,371,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 30 --------
2023-06-30 09:09:34,373,373,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 09:09:34,377,377,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 09:09:34,382,382,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 09:14:12,798,798,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.062970047647303 ---------
2023-06-30 09:14:12,799,799,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 31%|███       | 31/100 [2:25:26<5:21:00, 279.14s/it]2023-06-30 09:14:13,032,32,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 31 --------
2023-06-30 09:14:13,034,34,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 09:14:13,039,39,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 09:14:13,043,43,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 09:18:42,359,359,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.122810933992944 ---------
2023-06-30 09:18:42,359,359,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 32%|███▏      | 32/100 [2:29:56<5:13:05, 276.25s/it]2023-06-30 09:18:42,551,551,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 32 --------
2023-06-30 09:18:42,553,553,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 09:18:42,557,557,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 09:18:42,561,561,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 09:23:12,325,325,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.199516152793711 ---------
2023-06-30 09:23:12,328,328,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 33%|███▎      | 33/100 [2:34:26<5:06:23, 274.38s/it]2023-06-30 09:23:12,551,551,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 33 --------
2023-06-30 09:23:12,553,553,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 09:23:12,557,557,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 09:23:12,561,561,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 09:27:50,864,864,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1479825512929396 ---------
2023-06-30 09:27:50,864,864,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 34%|███▍      | 34/100 [2:39:04<5:03:11, 275.63s/it]2023-06-30 09:27:51,110,110,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 34 --------
2023-06-30 09:27:51,112,112,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 09:27:51,116,116,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 09:27:51,119,119,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 09:32:40,309,309,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.15665063532916 ---------
2023-06-30 09:32:40,310,310,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 35%|███▌      | 35/100 [2:43:54<5:03:06, 279.80s/it]2023-06-30 09:32:40,627,627,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 35 --------
2023-06-30 09:32:40,628,628,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 09:32:40,632,632,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 09:32:40,635,635,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 09:37:28,814,814,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1277657097036187 ---------
2023-06-30 09:37:28,814,814,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 36%|███▌      | 36/100 [2:48:42<5:01:12, 282.38s/it]2023-06-30 09:37:29,035,35,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 36 --------
2023-06-30 09:37:29,037,37,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 09:37:29,041,41,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 09:37:29,046,46,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 09:42:17,664,664,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.169095904989676 ---------
2023-06-30 09:42:17,664,664,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 37%|███▋      | 37/100 [2:53:31<4:58:30, 284.30s/it]2023-06-30 09:42:17,818,818,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 37 --------
2023-06-30 09:42:17,820,820,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 09:42:17,823,823,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 09:42:17,826,826,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 09:46:54,253,253,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.944342090324922 ---------
2023-06-30 09:46:54,254,254,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 38%|███▊      | 38/100 [2:58:08<4:51:25, 282.03s/it]2023-06-30 09:46:54,554,554,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 38 --------
2023-06-30 09:46:54,555,555,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 09:46:54,559,559,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 09:46:54,562,562,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 09:51:45,076,76,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.152183858677745 ---------
2023-06-30 09:51:45,076,76,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 39%|███▉      | 39/100 [3:02:59<4:49:24, 284.67s/it]2023-06-30 09:51:45,371,371,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 39 --------
2023-06-30 09:51:45,374,374,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 09:51:45,378,378,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 09:51:45,382,382,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 09:56:23,273,273,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.0865746465596287 ---------
2023-06-30 09:56:23,273,273,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 40%|████      | 40/100 [3:07:37<4:42:44, 282.75s/it]2023-06-30 09:56:23,644,644,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 40 --------
2023-06-30 09:56:23,646,646,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 09:56:23,649,649,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 09:56:23,661,661,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 10:01:04,030,30,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9746063154783438 ---------
2023-06-30 10:01:04,031,31,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 41%|████      | 41/100 [3:12:18<4:37:26, 282.15s/it]2023-06-30 10:01:04,400,400,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 41 --------
2023-06-30 10:01:04,402,402,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 10:01:04,406,406,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 10:01:04,409,409,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 10:05:43,811,811,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9767592941326173 ---------
2023-06-30 10:05:43,812,812,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 42%|████▏     | 42/100 [3:16:57<4:32:01, 281.41s/it]2023-06-30 10:05:44,069,69,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 42 --------
2023-06-30 10:05:44,071,71,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 10:05:44,075,75,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 10:05:44,077,77,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 10:10:21,247,247,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1473479226908903 ---------
2023-06-30 10:10:21,248,248,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 43%|████▎     | 43/100 [3:21:35<4:26:11, 280.20s/it]2023-06-30 10:10:21,444,444,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 43 --------
2023-06-30 10:10:21,445,445,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 10:10:21,454,454,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 10:10:21,454,454,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 10:15:02,358,358,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1428581292487006 ---------
2023-06-30 10:15:02,358,358,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 44%|████▍     | 44/100 [3:26:16<4:21:46, 280.47s/it]2023-06-30 10:15:02,545,545,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 44 --------
2023-06-30 10:15:02,548,548,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 10:15:02,553,553,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 10:15:02,559,559,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 10:19:44,180,180,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.957703028212894 ---------
2023-06-30 10:19:44,180,180,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 45%|████▌     | 45/100 [3:30:58<4:17:31, 280.93s/it]2023-06-30 10:19:44,555,555,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 45 --------
2023-06-30 10:19:44,557,557,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 10:19:44,561,561,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 10:19:44,563,563,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 10:24:27,005,5,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.212348998947577 ---------
2023-06-30 10:24:27,006,6,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 46%|████▌     | 46/100 [3:35:41<4:13:20, 281.49s/it]2023-06-30 10:24:27,346,346,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 46 --------
2023-06-30 10:24:27,347,347,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 10:24:27,351,351,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 10:24:27,354,354,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 10:29:06,929,929,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.130495450713418 ---------
2023-06-30 10:29:06,929,929,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 47%|████▋     | 47/100 [3:40:21<4:08:13, 281.01s/it]2023-06-30 10:29:07,244,244,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 47 --------
2023-06-30 10:29:07,245,245,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 10:29:07,249,249,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 10:29:07,252,252,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 10:33:52,569,569,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2783668765120884 ---------
2023-06-30 10:33:52,570,570,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 48%|████▊     | 48/100 [3:45:06<4:04:44, 282.40s/it]2023-06-30 10:33:52,871,871,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 48 --------
2023-06-30 10:33:52,873,873,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 10:33:52,877,877,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 10:33:52,881,881,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 10:38:24,385,385,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.211376795291223 ---------
2023-06-30 10:38:24,386,386,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 49%|████▉     | 49/100 [3:49:38<3:57:20, 279.23s/it]2023-06-30 10:38:24,717,717,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 49 --------
2023-06-30 10:38:24,719,719,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 10:38:24,724,724,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 10:38:24,726,726,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 10:43:04,458,458,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.0385761841792953 ---------
2023-06-30 10:43:04,458,458,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 50%|█████     | 50/100 [3:54:18<3:52:54, 279.48s/it]2023-06-30 10:43:04,790,790,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 50 --------
2023-06-30 10:43:04,792,792,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 10:43:04,795,795,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 10:43:04,799,799,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 10:47:53,260,260,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.233614468100396 ---------
2023-06-30 10:47:53,261,261,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 51%|█████     | 51/100 [3:59:07<3:50:31, 282.27s/it]2023-06-30 10:47:53,557,557,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 51 --------
2023-06-30 10:47:53,559,559,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 10:47:53,564,564,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 10:47:53,567,567,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 10:52:25,063,63,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9628579727458684 ---------
2023-06-30 10:52:25,064,64,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 52%|█████▏    | 52/100 [4:03:39<3:43:17, 279.12s/it]2023-06-30 10:52:25,325,325,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 52 --------
2023-06-30 10:52:25,327,327,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 10:52:25,332,332,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 10:52:25,335,335,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 10:57:14,378,378,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2920793294906616 ---------
2023-06-30 10:57:14,379,379,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 53%|█████▎    | 53/100 [4:08:28<3:41:01, 282.17s/it]2023-06-30 10:57:14,601,601,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 53 --------
2023-06-30 10:57:14,603,603,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 10:57:14,607,607,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 10:57:14,610,610,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 11:02:02,104,104,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1539207724007694 ---------
2023-06-30 11:02:02,105,105,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 54%|█████▍    | 54/100 [4:13:16<3:37:36, 283.83s/it]2023-06-30 11:02:02,307,307,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 54 --------
2023-06-30 11:02:02,309,309,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 11:02:02,318,318,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 11:02:02,320,320,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 11:06:34,395,395,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9186872027137063 ---------
2023-06-30 11:06:34,395,395,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 55%|█████▌    | 55/100 [4:17:48<3:30:18, 280.40s/it]2023-06-30 11:06:34,718,718,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 55 --------
2023-06-30 11:06:34,720,720,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 11:06:34,724,724,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 11:06:34,727,727,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 11:11:12,557,557,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1826588782397183 ---------
2023-06-30 11:11:12,557,557,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 56%|█████▌    | 56/100 [4:22:26<3:25:07, 279.71s/it]2023-06-30 11:11:12,809,809,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 56 --------
2023-06-30 11:11:12,811,811,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 11:11:12,815,815,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 11:11:12,819,819,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 11:16:02,576,576,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.248383102091876 ---------
2023-06-30 11:16:02,576,576,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 57%|█████▋    | 57/100 [4:27:16<3:22:40, 282.81s/it]2023-06-30 11:16:02,856,856,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 57 --------
2023-06-30 11:16:02,858,858,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 11:16:02,862,862,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 11:16:02,865,865,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 11:20:48,604,604,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2362958790988405 ---------
2023-06-30 11:20:48,607,607,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 58%|█████▊    | 58/100 [4:32:02<3:18:38, 283.78s/it]2023-06-30 11:20:48,882,882,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 58 --------
2023-06-30 11:20:48,890,890,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 11:20:48,893,893,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 11:20:48,896,896,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 11:25:39,000,0,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.26555860101838 ---------
2023-06-30 11:25:39,001,1,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 59%|█████▉    | 59/100 [4:36:53<3:15:17, 285.80s/it]2023-06-30 11:25:39,397,397,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 59 --------
2023-06-30 11:25:39,399,399,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 11:25:39,404,404,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 11:25:39,407,407,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 11:30:22,440,440,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2319692300463263 ---------
2023-06-30 11:30:22,441,441,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 60%|██████    | 60/100 [4:41:36<3:10:02, 285.07s/it]2023-06-30 11:30:22,758,758,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 60 --------
2023-06-30 11:30:22,760,760,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 11:30:22,764,764,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 11:30:22,768,768,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 11:34:55,319,319,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.8941853710196235 ---------
2023-06-30 11:34:55,320,320,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 61%|██████    | 61/100 [4:46:09<3:02:54, 281.40s/it]2023-06-30 11:34:55,613,613,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 61 --------
2023-06-30 11:34:55,614,614,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 11:34:55,618,618,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 11:34:55,620,620,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 11:39:43,684,684,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.249326707371934 ---------
2023-06-30 11:39:43,684,684,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 62%|██████▏   | 62/100 [4:50:57<2:59:32, 283.49s/it]2023-06-30 11:39:43,982,982,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 62 --------
2023-06-30 11:39:43,984,984,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 11:39:43,988,988,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 11:39:43,991,991,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 11:44:17,662,662,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9223862154917284 ---------
2023-06-30 11:44:17,663,663,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 63%|██████▎   | 63/100 [4:55:31<2:53:03, 280.64s/it]2023-06-30 11:44:17,973,973,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 63 --------
2023-06-30 11:44:17,975,975,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 11:44:17,987,987,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 11:44:17,990,990,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 11:49:01,045,45,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.195198335854167 ---------
2023-06-30 11:49:01,048,48,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 64%|██████▍   | 64/100 [5:00:15<2:48:52, 281.45s/it]2023-06-30 11:49:01,300,300,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 64 --------
2023-06-30 11:49:01,302,302,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 11:49:01,311,311,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 11:49:01,325,325,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 11:53:39,319,319,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2951846387745305 ---------
2023-06-30 11:53:39,320,320,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 65%|██████▌   | 65/100 [5:04:53<2:43:37, 280.50s/it]2023-06-30 11:53:39,603,603,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 65 --------
2023-06-30 11:53:39,605,605,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 11:53:39,609,609,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 11:53:39,613,613,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 11:58:15,680,680,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.0808584581721914 ---------
2023-06-30 11:58:15,681,681,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 66%|██████▌   | 66/100 [5:09:29<2:38:15, 279.27s/it]2023-06-30 11:58:15,999,999,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 66 --------
2023-06-30 11:58:16,001,1,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 11:58:16,006,6,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 11:58:16,009,9,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 12:02:52,094,94,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.0399543697183784 ---------
2023-06-30 12:02:52,097,97,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 67%|██████▋   | 67/100 [5:14:06<2:33:08, 278.44s/it]2023-06-30 12:02:52,505,505,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 67 --------
2023-06-30 12:02:52,508,508,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 12:02:52,512,512,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 12:02:52,516,516,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 12:07:36,234,234,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1932281960140574 ---------
2023-06-30 12:07:36,235,235,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 68%|██████▊   | 68/100 [5:18:50<2:29:24, 280.15s/it]2023-06-30 12:07:36,650,650,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 68 --------
2023-06-30 12:07:36,653,653,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 12:07:36,656,656,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 12:07:36,656,656,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 12:12:15,117,117,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1942711488174442 ---------
2023-06-30 12:12:15,119,119,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 69%|██████▉   | 69/100 [5:23:29<2:24:32, 279.75s/it]2023-06-30 12:12:15,450,450,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 69 --------
2023-06-30 12:12:15,453,453,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 12:12:15,458,458,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 12:12:15,462,462,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 12:16:58,839,839,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.025036920200695 ---------
2023-06-30 12:16:58,842,842,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 70%|███████   | 70/100 [5:28:12<2:20:27, 280.92s/it]2023-06-30 12:16:59,100,100,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 70 --------
2023-06-30 12:16:59,103,103,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 12:16:59,109,109,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 12:16:59,113,113,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 12:21:41,765,765,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.0618247633630578 ---------
2023-06-30 12:21:41,766,766,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 71%|███████   | 71/100 [5:32:55<2:16:05, 281.57s/it]2023-06-30 12:21:42,183,183,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 71 --------
2023-06-30 12:21:42,185,185,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 12:21:42,191,191,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 12:21:42,196,196,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 12:26:26,164,164,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2529175715012983 ---------
2023-06-30 12:26:26,166,166,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 72%|███████▏  | 72/100 [5:37:40<2:11:47, 282.41s/it]2023-06-30 12:26:26,557,557,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 72 --------
2023-06-30 12:26:26,560,560,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 12:26:26,565,565,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 12:26:26,569,569,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 12:31:08,467,467,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.179168997290121 ---------
2023-06-30 12:31:08,468,468,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 73%|███████▎  | 73/100 [5:42:22<2:07:02, 282.32s/it]2023-06-30 12:31:08,682,682,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 73 --------
2023-06-30 12:31:08,685,685,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 12:31:08,695,695,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 12:31:08,695,695,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 12:35:48,482,482,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1614120135253128 ---------
2023-06-30 12:35:48,482,482,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 74%|███████▍  | 74/100 [5:47:02<2:02:02, 281.62s/it]2023-06-30 12:35:48,663,663,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 74 --------
2023-06-30 12:35:48,668,668,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 12:35:48,688,688,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 12:35:48,690,690,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 12:40:18,616,616,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.0912524299188093 ---------
2023-06-30 12:40:18,618,618,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 75%|███████▌  | 75/100 [5:51:32<1:55:55, 278.21s/it]2023-06-30 12:40:18,907,907,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 75 --------
2023-06-30 12:40:18,909,909,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 12:40:18,914,914,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 12:40:18,918,918,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 12:44:51,483,483,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.29289749472148 ---------
2023-06-30 12:44:51,483,483,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 76%|███████▌  | 76/100 [5:56:05<1:50:38, 276.59s/it]2023-06-30 12:44:51,723,723,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 76 --------
2023-06-30 12:44:51,725,725,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 12:44:51,730,730,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 12:44:51,733,733,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 12:49:33,865,865,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.045028778639707 ---------
2023-06-30 12:49:33,866,866,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 77%|███████▋  | 77/100 [6:00:47<1:46:41, 278.33s/it]2023-06-30 12:49:34,097,97,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 77 --------
2023-06-30 12:49:34,099,99,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 12:49:34,104,104,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 12:49:34,120,120,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 12:54:10,515,515,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.923246994106607 ---------
2023-06-30 12:54:10,516,516,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 78%|███████▊  | 78/100 [6:05:24<1:41:52, 277.82s/it]2023-06-30 12:54:10,733,733,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 78 --------
2023-06-30 12:54:10,736,736,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 12:54:10,745,745,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 12:54:10,759,759,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 12:59:00,791,791,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2376917761496524 ---------
2023-06-30 12:59:00,791,791,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 79%|███████▉  | 79/100 [6:10:14<1:38:33, 281.60s/it]2023-06-30 12:59:01,142,142,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 79 --------
2023-06-30 12:59:01,145,145,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 12:59:01,151,151,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 12:59:01,155,155,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 13:03:53,558,558,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2583913803100586 ---------
2023-06-30 13:03:53,560,560,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 80%|████████  | 80/100 [6:15:07<1:34:59, 284.95s/it]2023-06-30 13:03:53,934,934,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 80 --------
2023-06-30 13:03:53,936,936,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 13:03:53,941,941,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 13:03:53,945,945,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 13:08:36,557,557,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9910267149098217 ---------
2023-06-30 13:08:36,557,557,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 81%|████████  | 81/100 [6:19:50<1:30:02, 284.37s/it]2023-06-30 13:08:36,929,929,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 81 --------
2023-06-30 13:08:36,932,932,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 13:08:36,937,937,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 13:08:36,940,940,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 13:13:22,528,528,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1909173663536254 ---------
2023-06-30 13:13:22,529,529,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 82%|████████▏ | 82/100 [6:24:36<1:25:26, 284.81s/it]2023-06-30 13:13:22,770,770,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 82 --------
2023-06-30 13:13:22,772,772,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 13:13:22,777,777,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 13:13:22,781,781,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 13:17:56,572,572,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.0117385256188838 ---------
2023-06-30 13:17:56,573,573,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 83%|████████▎ | 83/100 [6:29:10<1:19:46, 281.57s/it]2023-06-30 13:17:56,787,787,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 83 --------
2023-06-30 13:17:56,789,789,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 13:17:56,804,804,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 13:17:56,808,808,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 13:22:45,242,242,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2005791480398993 ---------
2023-06-30 13:22:45,242,242,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 84%|████████▍ | 84/100 [6:33:59<1:15:39, 283.73s/it]2023-06-30 13:22:45,565,565,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 84 --------
2023-06-30 13:22:45,568,568,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 13:22:45,574,574,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 13:22:45,581,581,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 13:27:27,250,250,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.0598377973179924 ---------
2023-06-30 13:27:27,251,251,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 85%|████████▌ | 85/100 [6:38:41<1:10:47, 283.19s/it]2023-06-30 13:27:27,479,479,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 85 --------
2023-06-30 13:27:27,481,481,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 13:27:27,485,485,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 13:27:27,489,489,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 13:32:01,614,614,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.191934855231507 ---------
2023-06-30 13:32:01,615,615,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 86%|████████▌ | 86/100 [6:43:15<1:05:27, 280.53s/it]2023-06-30 13:32:01,817,817,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 86 --------
2023-06-30 13:32:01,819,819,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 13:32:01,824,824,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 13:32:01,827,827,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 13:36:42,259,259,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.243675894823603 ---------
2023-06-30 13:36:42,261,261,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 87%|████████▋ | 87/100 [6:47:56<1:00:48, 280.62s/it]2023-06-30 13:36:42,633,633,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 87 --------
2023-06-30 13:36:42,635,635,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 13:36:42,640,640,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 13:36:42,644,644,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 13:41:24,507,507,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.125859027559107 ---------
2023-06-30 13:41:24,508,508,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 88%|████████▊ | 88/100 [6:52:38<56:12, 281.07s/it]  2023-06-30 13:41:24,757,757,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 88 --------
2023-06-30 13:41:24,759,759,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 13:41:24,763,763,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 13:41:24,763,763,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 13:46:10,820,820,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.088892452164807 ---------
2023-06-30 13:46:10,821,821,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 89%|████████▉ | 89/100 [6:57:24<51:48, 282.63s/it]2023-06-30 13:46:11,014,14,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 89 --------
2023-06-30 13:46:11,017,17,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 13:46:11,022,22,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 13:46:11,026,26,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 13:50:56,251,251,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.062041599642147 ---------
2023-06-30 13:50:56,251,251,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 90%|█████████ | 90/100 [7:02:10<47:15, 283.53s/it]2023-06-30 13:50:56,656,656,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 90 --------
2023-06-30 13:50:56,658,658,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 13:50:56,662,662,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 13:50:56,666,666,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 13:55:33,763,763,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2660416533577847 ---------
2023-06-30 13:55:33,767,767,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 91%|█████████ | 91/100 [7:06:47<42:15, 281.70s/it]2023-06-30 13:55:34,097,97,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 91 --------
2023-06-30 13:55:34,100,100,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 13:55:34,106,106,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 13:55:34,108,108,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 14:00:23,215,215,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2130677212368357 ---------
2023-06-30 14:00:23,216,216,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 92%|█████████▏| 92/100 [7:11:37<37:52, 284.00s/it]2023-06-30 14:00:23,457,457,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 92 --------
2023-06-30 14:00:23,459,459,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 14:00:23,464,464,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 14:00:23,468,468,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 14:05:04,099,99,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2393273651938546 ---------
2023-06-30 14:05:04,101,101,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 93%|█████████▎| 93/100 [7:16:18<33:01, 283.07s/it]2023-06-30 14:05:04,342,342,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 93 --------
2023-06-30 14:05:04,345,345,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 14:05:04,356,356,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 14:05:04,356,356,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 14:09:45,674,674,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2727618937126617 ---------
2023-06-30 14:09:45,675,675,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 94%|█████████▍| 94/100 [7:20:59<28:15, 282.62s/it]2023-06-30 14:09:45,928,928,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 94 --------
2023-06-30 14:09:45,930,930,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 14:09:45,936,936,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 14:09:45,940,940,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 14:14:29,505,505,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.136552204864777 ---------
2023-06-30 14:14:29,505,505,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 95%|█████████▌| 95/100 [7:25:43<23:34, 282.98s/it]2023-06-30 14:14:29,756,756,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 95 --------
2023-06-30 14:14:29,759,759,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 14:14:29,763,763,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 14:14:29,767,767,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 14:19:09,142,142,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.291989575732838 ---------
2023-06-30 14:19:09,143,143,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 96%|█████████▌| 96/100 [7:30:23<18:48, 282.02s/it]2023-06-30 14:19:09,537,537,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 96 --------
2023-06-30 14:19:09,539,539,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 14:19:09,544,544,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 14:19:09,548,548,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 14:23:46,514,514,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.238691438328136 ---------
2023-06-30 14:23:46,515,515,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 97%|█████████▋| 97/100 [7:35:00<14:01, 280.61s/it]2023-06-30 14:23:46,846,846,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 97 --------
2023-06-30 14:23:46,849,849,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 14:23:46,854,854,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 14:23:46,857,857,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 14:28:23,796,796,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2559100409800354 ---------
2023-06-30 14:28:23,796,796,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 98%|█████████▊| 98/100 [7:39:37<09:19, 279.59s/it]2023-06-30 14:28:24,068,68,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 98 --------
2023-06-30 14:28:24,070,70,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 14:28:24,073,73,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 14:28:24,073,73,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 14:33:00,932,932,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1366801207715813 ---------
2023-06-30 14:33:00,933,933,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 99%|█████████▉| 99/100 [7:44:14<04:38, 278.85s/it]2023-06-30 14:33:01,175,175,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 99 --------
2023-06-30 14:33:01,178,178,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-06-30 14:33:01,183,183,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-06-30 14:33:01,187,187,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-06-30 14:37:45,618,618,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.0793398049744694 ---------
2023-06-30 14:37:45,619,619,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

100%|██████████| 100/100 [7:48:59<00:00, 280.64s/it]
100%|██████████| 100/100 [7:48:59<00:00, 281.40s/it]
2023-06-30 14:37:46,162,162,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current is (10, 60) --------
2023-06-30 14:37:46,163,163,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size4=======

0it [00:00, ?it/s]
1it [00:36, 36.23s/it]
2it [01:06, 32.70s/it]
3it [01:26, 26.88s/it]
3it [01:26, 28.83s/it]
2023-06-30 14:39:26,981,981,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
2023-06-30 14:40:05,035,35,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current is (20, 70) --------
2023-06-30 14:40:05,041,41,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size4=======

0it [00:00, ?it/s]
1it [00:10, 10.11s/it]
2it [00:16,  7.70s/it]
3it [00:19,  5.86s/it]
3it [00:19,  6.63s/it]
2023-06-30 14:40:31,146,146,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
2023-06-30 14:41:28,868,868,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current is (30, 80) --------
2023-06-30 14:41:28,873,873,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size4=======

0it [00:00, ?it/s]
1it [00:15, 15.36s/it]
2it [00:25, 12.50s/it]
3it [00:32,  9.92s/it]
3it [00:32, 10.94s/it]
2023-06-30 14:42:09,530,530,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
2023-06-30 14:43:29,712,712,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current is (40, 90) --------
2023-06-30 14:43:29,720,720,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size4=======

0it [00:00, ?it/s]
1it [00:21, 21.97s/it]
2it [00:38, 18.55s/it]
3it [00:48, 14.68s/it]
3it [00:48, 16.10s/it]
2023-06-30 14:44:28,601,601,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
2023-06-30 14:46:17,860,860,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current is (50, 100) --------
2023-06-30 14:46:17,866,866,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size4=======

0it [00:00, ?it/s]
1it [00:31, 31.25s/it]
2it [00:55, 27.08s/it]
3it [01:11, 21.95s/it]
3it [01:11, 23.79s/it]
2023-06-30 14:47:45,726,726,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
2023-06-30 14:50:10,055,55,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current is (60, 110) --------
2023-06-30 14:50:10,060,60,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size4=======

0it [00:00, ?it/s]
1it [00:43, 43.17s/it]
2it [01:18, 38.35s/it]
3it [01:41, 31.67s/it]
3it [01:41, 33.99s/it]
2023-06-30 14:52:15,612,612,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished eval ==========
2023-06-30 14:55:16,898,898,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current is (70, 120) --------
2023-06-30 14:55:16,903,903,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start eval ======= batch_size4=======

0it [00:00, ?it/s]
1it [01:01, 61.63s/it]
2it [01:52, 55.29s/it]ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).
 
2it [02:21, 70.94s/it]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 45693) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 269, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 234, in run
    sim_graph = eval(graph, batch_size//num_workers, num_workers, encoder, generator, veh_depart, veh_route, changable_feature_names, hetero_feat_dim, logger, device, training_step+pred_step*(i+1), pred_step)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_exp.py", line 69, in eval
    for i, cur_graphs in tqdm(enumerate(val_loader)):
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1325, in _get_data
    success, data = self._try_get_data()s
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1176, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 45693) exited unexpectedly
2023-07-03 02:08:33,574,574,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== process hangzhou_test500_50_4_4_pred_step_10  is running! ===========
2023-07-03 02:08:40,844,844,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
2023-07-03 02:14:36,880,880,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 02:49:17,672,672,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== process hangzhou_test500_50_4_4_pred_step_10  is running! ===========
2023-07-03 02:49:24,945,945,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
2023-07-03 02:50:09,183,183,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 02:51:21,597,597,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= 100_4_1 =========
2023-07-03 02:51:22,707,707,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
/mnt/workspace/wangding/Desktop/TransWorldNG/experiment/bologna_clean/data/test500/out_dim_50_n_heads_4_n_layer_4_pred_step_10/encoder.pth
========== Finish load preTrain model ==========

  0%|          | 0/100 [00:00<?, ?it/s]2023-07-03 02:51:22,733,733,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-07-03 02:51:22,735,735,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 02:51:22,738,738,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 02:51:22,741,741,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 02:56:11,810,810,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.554677226326682 ---------
2023-07-03 02:56:11,811,811,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  1%|          | 1/100 [04:49<7:57:38, 289.48s/it]2023-07-03 02:56:12,215,215,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 1 --------
2023-07-03 02:56:12,217,217,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 02:56:12,220,220,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 02:56:12,223,223,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 03:00:37,342,342,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.256864631717855 ---------
2023-07-03 03:00:37,343,343,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  2%|▏         | 2/100 [09:14<7:29:36, 275.28s/it]2023-07-03 03:00:37,546,546,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 2 --------
2023-07-03 03:00:37,548,548,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 03:00:37,552,552,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 03:00:37,556,556,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 03:05:30,185,185,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.4429231015118686 ---------
2023-07-03 03:05:30,186,186,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  3%|▎         | 3/100 [14:07<7:38:04, 283.35s/it]2023-07-03 03:05:30,504,504,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 3 --------
2023-07-03 03:05:30,506,506,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 03:05:30,510,510,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 03:05:30,513,513,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 03:10:15,364,364,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.3374027989127417 ---------
2023-07-03 03:10:15,365,365,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  4%|▍         | 4/100 [18:52<7:34:26, 284.02s/it]2023-07-03 03:10:15,563,563,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 4 --------
2023-07-03 03:10:15,565,565,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 03:10:15,570,570,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 03:10:15,573,573,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 03:14:49,651,651,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.3488068269057707 ---------
2023-07-03 03:14:49,652,652,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  5%|▌         | 5/100 [23:27<7:24:08, 280.51s/it]2023-07-03 03:14:49,844,844,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 5 --------
2023-07-03 03:14:49,845,845,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 03:14:49,849,849,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 03:14:49,852,852,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 03:19:36,780,780,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.3058245832269844 ---------
2023-07-03 03:19:36,780,780,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  6%|▌         | 6/100 [28:14<7:23:00, 282.77s/it]2023-07-03 03:19:37,005,5,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 6 --------
2023-07-03 03:19:37,007,7,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 03:19:37,010,10,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 03:19:37,014,14,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 03:24:28,101,101,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2749597110192883 ---------
2023-07-03 03:24:28,102,102,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  7%|▋         | 7/100 [33:05<7:22:39, 285.58s/it]2023-07-03 03:24:28,380,380,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 7 --------
2023-07-03 03:24:28,382,382,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 03:24:28,386,386,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 03:24:28,390,390,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 03:29:13,232,232,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.193615050986409 ---------
2023-07-03 03:29:13,232,232,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  8%|▊         | 8/100 [37:50<7:17:41, 285.45s/it]2023-07-03 03:29:13,538,538,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 8 --------
2023-07-03 03:29:13,541,541,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 03:29:13,546,546,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 03:29:13,549,549,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 03:33:36,401,401,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1854425235228105 ---------
2023-07-03 03:33:36,402,402,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

  9%|▉         | 9/100 [42:13<7:02:19, 278.46s/it]2023-07-03 03:33:36,622,622,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 9 --------
2023-07-03 03:33:36,624,624,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 03:33:36,628,628,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 03:33:36,631,631,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 03:38:23,209,209,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2276986315846443 ---------
2023-07-03 03:38:23,210,210,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 10%|█         | 10/100 [47:00<7:01:38, 281.09s/it]2023-07-03 03:38:23,623,623,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 10 --------
2023-07-03 03:38:23,625,625,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 03:38:23,629,629,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 03:38:23,631,631,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 03:43:09,889,889,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1835769496180792 ---------
2023-07-03 03:43:09,893,893,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 11%|█         | 11/100 [51:47<6:59:25, 282.76s/it]2023-07-03 03:43:10,161,161,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 11 --------
2023-07-03 03:43:10,163,163,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 03:43:10,168,168,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 03:43:10,172,172,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 03:47:43,946,946,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.049697458744049 ---------
2023-07-03 03:47:43,947,947,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 12%|█▏        | 12/100 [56:21<6:50:50, 280.12s/it]2023-07-03 03:47:44,230,230,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 12 --------
2023-07-03 03:47:44,232,232,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 03:47:44,236,236,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 03:47:44,240,240,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 03:52:22,778,778,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.115832953290506 ---------
2023-07-03 03:52:22,779,779,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 13%|█▎        | 13/100 [1:01:00<6:45:35, 279.72s/it]2023-07-03 03:52:23,037,37,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 13 --------
2023-07-03 03:52:23,039,39,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 03:52:23,043,43,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 03:52:23,048,48,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 03:57:04,682,682,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9671365285122937 ---------
2023-07-03 03:57:04,682,682,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 14%|█▍        | 14/100 [1:05:42<6:41:52, 280.37s/it]2023-07-03 03:57:04,920,920,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 14 --------
2023-07-03 03:57:04,922,922,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 03:57:04,931,931,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 03:57:04,944,944,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 04:01:47,700,700,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.299421125430275 ---------
2023-07-03 04:01:47,701,701,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 15%|█▌        | 15/100 [1:10:25<6:38:21, 281.19s/it]2023-07-03 04:01:48,016,16,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 15 --------
2023-07-03 04:01:48,018,18,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 04:01:48,023,23,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 04:01:48,025,25,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 04:06:27,946,946,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1057232157750563 ---------
2023-07-03 04:06:27,947,947,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 16%|█▌        | 16/100 [1:15:05<6:33:19, 280.95s/it]2023-07-03 04:06:28,391,391,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 16 --------
2023-07-03 04:06:28,393,393,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 04:06:28,393,393,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 04:06:28,397,397,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 04:11:14,319,319,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.196182343770157 ---------
2023-07-03 04:11:14,320,320,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 17%|█▋        | 17/100 [1:19:51<6:30:48, 282.52s/it]2023-07-03 04:11:14,555,555,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 17 --------
2023-07-03 04:11:14,558,558,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 04:11:14,561,561,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 04:11:14,565,565,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 04:16:02,000,0,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1705736829475923 ---------
2023-07-03 04:16:02,001,1,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 18%|█▊        | 18/100 [1:24:39<6:28:14, 284.08s/it]2023-07-03 04:16:02,278,278,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 18 --------
2023-07-03 04:16:02,280,280,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 04:16:02,285,285,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 04:16:02,289,289,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 04:20:32,935,935,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2488623044707556 ---------
2023-07-03 04:20:32,938,938,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 19%|█▉        | 19/100 [1:29:10<6:18:10, 280.13s/it]2023-07-03 04:20:33,214,214,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 19 --------
2023-07-03 04:20:33,216,216,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 04:20:33,221,221,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 04:20:33,225,225,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 04:25:18,829,829,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2730956456877967 ---------
2023-07-03 04:25:18,830,830,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 20%|██        | 20/100 [1:33:56<6:15:48, 281.85s/it]2023-07-03 04:25:19,072,72,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 20 --------
2023-07-03 04:25:19,074,74,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 04:25:19,077,77,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 04:25:19,081,81,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 04:30:07,059,59,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.129993002861738 ---------
2023-07-03 04:30:07,059,59,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 21%|██        | 21/100 [1:38:44<6:13:37, 283.77s/it]2023-07-03 04:30:07,298,298,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 21 --------
2023-07-03 04:30:07,300,300,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 04:30:07,306,306,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 04:30:07,310,310,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 04:34:48,633,633,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.240040906450965 ---------
2023-07-03 04:34:48,634,634,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 22%|██▏       | 22/100 [1:43:26<6:08:04, 283.13s/it]2023-07-03 04:34:48,945,945,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 22 --------
2023-07-03 04:34:48,947,947,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 04:34:48,951,951,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 04:34:48,954,954,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 04:39:36,841,841,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1309574520723387 ---------
2023-07-03 04:39:36,843,843,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 23%|██▎       | 23/100 [1:48:14<6:05:18, 284.66s/it]2023-07-03 04:39:37,177,177,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 23 --------
2023-07-03 04:39:37,179,179,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 04:39:37,184,184,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 04:39:37,187,187,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 04:44:18,414,414,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.27484644187445 ---------
2023-07-03 04:44:18,415,415,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 24%|██▍       | 24/100 [1:52:55<5:59:21, 283.70s/it]2023-07-03 04:44:18,636,636,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 24 --------
2023-07-03 04:44:18,638,638,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 04:44:18,642,642,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 04:44:18,646,646,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 04:48:46,443,443,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9310620616782794 ---------
2023-07-03 04:48:46,444,444,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 25%|██▌       | 25/100 [1:57:23<5:48:42, 278.97s/it]2023-07-03 04:48:46,570,570,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 25 --------
2023-07-03 04:48:46,572,572,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 04:48:46,577,577,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 04:48:46,580,580,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 04:53:17,096,96,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.8238304757343775 ---------
2023-07-03 04:53:17,097,97,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 26%|██▌       | 26/100 [2:01:54<5:41:00, 276.49s/it]2023-07-03 04:53:17,285,285,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 26 --------
2023-07-03 04:53:17,287,287,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 04:53:17,291,291,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 04:53:17,294,294,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 04:57:53,734,734,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2120942094109277 ---------
2023-07-03 04:57:53,735,735,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 27%|██▋       | 27/100 [2:06:31<5:36:28, 276.55s/it]2023-07-03 04:57:53,982,982,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 27 --------
2023-07-03 04:57:53,984,984,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 04:57:53,988,988,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 04:57:53,991,991,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 05:02:25,755,755,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1514325069094244 ---------
2023-07-03 05:02:25,756,756,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 28%|██▊       | 28/100 [2:11:03<5:30:14, 275.20s/it]2023-07-03 05:02:26,015,15,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 28 --------
2023-07-03 05:02:26,017,17,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 05:02:26,021,21,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 05:02:26,025,25,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 05:07:07,732,732,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.160074256021868 ---------
2023-07-03 05:07:07,733,733,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 29%|██▉       | 29/100 [2:15:45<5:28:04, 277.24s/it]2023-07-03 05:07:08,025,25,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 29 --------
2023-07-03 05:07:08,027,27,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 05:07:08,031,31,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 05:07:08,034,34,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 05:11:50,659,659,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.208109550347382 ---------
2023-07-03 05:11:50,661,661,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 30%|███       | 30/100 [2:20:28<5:25:26, 278.95s/it]2023-07-03 05:11:50,953,953,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 30 --------
2023-07-03 05:11:50,956,956,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 05:11:50,959,959,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 05:11:50,962,962,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 05:16:28,996,996,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.0594603392210873 ---------
2023-07-03 05:16:28,997,997,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 31%|███       | 31/100 [2:25:06<5:20:33, 278.75s/it]2023-07-03 05:16:29,227,227,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 31 --------
2023-07-03 05:16:29,229,229,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 05:16:29,233,233,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 05:16:29,237,237,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 05:21:01,930,930,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1195745140483435 ---------
2023-07-03 05:21:01,931,931,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 32%|███▏      | 32/100 [2:29:39<5:13:55, 276.99s/it]2023-07-03 05:21:02,121,121,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 32 --------
2023-07-03 05:21:02,123,123,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 05:21:02,126,126,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 05:21:02,129,129,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 05:25:31,259,259,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.196058442646807 ---------
2023-07-03 05:25:31,260,260,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 33%|███▎      | 33/100 [2:34:08<5:06:45, 274.70s/it]2023-07-03 05:25:31,485,485,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 33 --------
2023-07-03 05:25:31,487,487,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 05:25:31,491,491,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 05:25:31,493,493,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 05:30:08,794,794,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1455981650135736 ---------
2023-07-03 05:30:08,795,795,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 34%|███▍      | 34/100 [2:38:46<5:03:09, 275.59s/it]2023-07-03 05:30:09,158,158,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 34 --------
2023-07-03 05:30:09,160,160,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 05:30:09,167,167,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 05:30:09,171,171,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 05:35:10,739,739,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.153755496848713 ---------
2023-07-03 05:35:10,740,740,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 35%|███▌      | 35/100 [2:43:48<5:07:05, 283.48s/it]2023-07-03 05:35:11,030,30,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 35 --------
2023-07-03 05:35:11,030,30,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 05:35:11,030,30,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 05:35:11,033,33,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 05:40:03,321,321,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.126274062828584 ---------
2023-07-03 05:40:03,322,322,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 36%|███▌      | 36/100 [2:48:40<5:05:17, 286.21s/it]2023-07-03 05:40:03,608,608,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 36 --------
2023-07-03 05:40:03,611,611,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 05:40:03,615,615,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 05:40:03,618,618,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 05:44:52,480,480,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.166308969259262 ---------
2023-07-03 05:44:52,481,481,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 37%|███▋      | 37/100 [2:53:29<5:01:25, 287.07s/it]2023-07-03 05:44:52,687,687,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 37 --------
2023-07-03 05:44:52,687,687,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 05:44:52,687,687,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 05:44:52,687,687,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 05:49:29,017,17,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9432386227629401 ---------
2023-07-03 05:49:29,018,18,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 38%|███▊      | 38/100 [2:58:06<4:53:23, 283.92s/it]2023-07-03 05:49:29,273,273,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 38 --------
2023-07-03 05:49:29,275,275,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 05:49:29,279,279,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 05:49:29,282,282,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 05:54:13,797,797,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.149151244793426 ---------
2023-07-03 05:54:13,797,797,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 39%|███▉      | 39/100 [3:02:51<4:48:55, 284.19s/it]2023-07-03 05:54:14,096,96,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 39 --------
2023-07-03 05:54:14,098,98,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 05:54:14,103,103,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 05:54:14,106,106,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 05:58:51,109,109,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.084039720621976 ---------
2023-07-03 05:58:51,110,110,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 40%|████      | 40/100 [3:07:28<4:42:08, 282.15s/it]2023-07-03 05:58:51,464,464,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 40 --------
2023-07-03 05:58:51,466,466,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 05:58:51,471,471,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 05:58:51,474,474,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 06:03:36,442,442,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9712826123630458 ---------
2023-07-03 06:03:36,443,443,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 41%|████      | 41/100 [3:12:14<4:38:22, 283.10s/it]2023-07-03 06:03:36,777,777,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 41 --------
2023-07-03 06:03:36,780,780,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 06:03:36,784,784,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 06:03:36,787,787,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 06:08:17,930,930,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.974860375069759 ---------
2023-07-03 06:08:17,931,931,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 42%|████▏     | 42/100 [3:16:55<4:33:11, 282.61s/it]2023-07-03 06:08:18,247,247,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 42 --------
2023-07-03 06:08:18,249,249,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 06:08:18,254,254,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 06:08:18,257,257,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 06:12:55,209,209,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1447009156373413 ---------
2023-07-03 06:12:55,210,210,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 43%|████▎     | 43/100 [3:21:32<4:26:55, 280.97s/it]2023-07-03 06:12:55,405,405,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 43 --------
2023-07-03 06:12:55,407,407,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 06:12:55,410,410,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 06:12:55,414,414,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 06:17:36,203,203,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.138550741259347 ---------
2023-07-03 06:17:36,203,203,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 44%|████▍     | 44/100 [3:26:13<4:22:15, 280.99s/it]2023-07-03 06:17:36,439,439,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 44 --------
2023-07-03 06:17:36,441,441,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 06:17:36,445,445,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 06:17:36,448,448,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 06:22:18,824,824,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9550780425356193 ---------
2023-07-03 06:22:18,825,825,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 45%|████▌     | 45/100 [3:30:56<4:18:02, 281.50s/it]2023-07-03 06:22:19,132,132,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 45 --------
2023-07-03 06:22:19,134,134,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 06:22:19,137,137,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 06:22:19,140,140,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 06:27:02,062,62,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2105721004984598 ---------
2023-07-03 06:27:02,063,63,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 46%|████▌     | 46/100 [3:35:39<4:13:49, 282.03s/it]2023-07-03 06:27:02,398,398,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 46 --------
2023-07-03 06:27:02,400,400,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 06:27:02,403,403,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 06:27:02,406,406,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 06:31:31,890,890,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== process HighD_highway02_50_4_4_pred_step_10  is running! ===========
2023-07-03 06:31:32,172,172,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
       height  width       x  ...      y  yAcceleration  yVelocity
0        2.50  19.81  413.22  ...  25.65           0.04       0.16
1        2.50  12.13  363.67  ...  25.21           0.02       0.09
2        2.50  12.13  364.56  ...  25.21           0.02       0.09
3        2.50  12.13  365.46  ...  25.22           0.02       0.09
4        2.50  12.13  366.37  ...  25.22           0.02       0.09
...       ...    ...     ...  ...    ...            ...        ...
22197    1.92   5.00    6.33  ...  21.73          -0.00      -0.18
22198    1.92   5.00    7.66  ...  21.72          -0.00      -0.18
22502    1.82   4.04  406.76  ...   9.27          -0.00       0.09
22503    1.82   4.04  405.81  ...   9.27          -0.01       0.08
22504    1.82   4.04  404.82  ...   9.28          -0.01       0.08

[19131 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-07-03 06:31:39,197,197,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 06:31:39,374,374,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1284006292169746 ---------
2023-07-03 06:31:39,375,375,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 47%|████▋     | 47/100 [3:40:16<4:07:52, 280.61s/it]2023-07-03 06:31:39,706,706,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 47 --------
2023-07-03 06:31:39,708,708,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 06:31:39,711,711,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 06:31:39,714,714,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 06:32:00,692,692,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= 10_50_1 =========
2023-07-03 06:32:01,574,574,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 286, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 217, in run
    encoder.load_state_dict(torch.load(encoder_path))
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/serialization.py", line 699, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/workspace/wangding/Desktop/TransWorldNG/experiment/HighD/data/highway02/preTrainModel/encoder.pth'
/mnt/workspace/wangding/Desktop/TransWorldNG/experiment/HighD/data/highway02/preTrainModel/encoder.pth
2023-07-03 06:32:53,110,110,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== process HighD_highway02_50_4_4_pred_step_10  is running! ===========
2023-07-03 06:32:53,393,393,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
       height  width       x  ...      y  yAcceleration  yVelocity
0        2.50  19.81  413.22  ...  25.65           0.04       0.16
1        2.50  12.13  363.67  ...  25.21           0.02       0.09
2        2.50  12.13  364.56  ...  25.21           0.02       0.09
3        2.50  12.13  365.46  ...  25.22           0.02       0.09
4        2.50  12.13  366.37  ...  25.22           0.02       0.09
...       ...    ...     ...  ...    ...            ...        ...
22197    1.92   5.00    6.33  ...  21.73          -0.00      -0.18
22198    1.92   5.00    7.66  ...  21.72          -0.00      -0.18
22502    1.82   4.04  406.76  ...   9.27          -0.00       0.09
22503    1.82   4.04  405.81  ...   9.27          -0.01       0.08
22504    1.82   4.04  404.82  ...   9.28          -0.01       0.08

[19131 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-07-03 06:33:00,479,479,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 06:33:22,057,57,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= 10_50_1 =========
2023-07-03 06:33:22,887,887,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 286, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 217, in run
    encoder.load_state_dict(torch.load(encoder_path))
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/serialization.py", line 699, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/workspace/wangding/Desktop/TransWorldNG/experiment/HighD/data/highway02/preTrainModel/out_dim_100_n_heads_4_n_layer_4_pred_step_10/encoder.pth'
/mnt/workspace/wangding/Desktop/TransWorldNG/experiment/HighD/data/highway02/preTrainModel/out_dim_100_n_heads_4_n_layer_4_pred_step_10/encoder.pth
2023-07-03 06:36:25,488,488,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.277023194357753 ---------
2023-07-03 06:36:25,489,489,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 48%|████▊     | 48/100 [3:45:03<4:04:37, 282.26s/it]2023-07-03 06:36:25,798,798,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 48 --------
2023-07-03 06:36:25,800,800,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 06:36:25,803,803,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 06:36:25,806,806,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 06:40:57,416,416,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2109752205962483 ---------
2023-07-03 06:40:57,417,417,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 49%|████▉     | 49/100 [3:49:34<3:57:16, 279.15s/it]2023-07-03 06:40:57,692,692,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 49 --------
2023-07-03 06:40:57,694,694,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 06:40:57,697,697,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 06:40:57,700,700,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 06:45:40,541,541,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.039384768598459 ---------
2023-07-03 06:45:40,541,541,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 50%|█████     | 50/100 [3:54:18<3:53:36, 280.33s/it]2023-07-03 06:45:40,790,790,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 50 --------
2023-07-03 06:45:40,792,792,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 06:45:40,795,795,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 06:45:40,799,799,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 06:49:07,737,737,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== process HighD_highway02_50_4_4_pred_step_10  is running! ===========
2023-07-03 06:49:08,017,17,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
       height  width       x  ...      y  yAcceleration  yVelocity
0        2.50  19.81  413.22  ...  25.65           0.04       0.16
1        2.50  12.13  363.67  ...  25.21           0.02       0.09
2        2.50  12.13  364.56  ...  25.21           0.02       0.09
3        2.50  12.13  365.46  ...  25.22           0.02       0.09
4        2.50  12.13  366.37  ...  25.22           0.02       0.09
...       ...    ...     ...  ...    ...            ...        ...
22197    1.92   5.00    6.33  ...  21.73          -0.00      -0.18
22198    1.92   5.00    7.66  ...  21.72          -0.00      -0.18
22502    1.82   4.04  406.76  ...   9.27          -0.00       0.09
22503    1.82   4.04  405.81  ...   9.27          -0.01       0.08
22504    1.82   4.04  404.82  ...   9.28          -0.01       0.08

[19131 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-07-03 06:49:15,061,61,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 06:49:36,440,440,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= 10_50_1 =========
2023-07-03 06:49:37,442,442,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 286, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 217, in run
    encoder.load_state_dict(torch.load(encoder_path))
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/serialization.py", line 699, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/workspace/wangding/Desktop/TransWorldNG/experiment/HighD/data/highway02/preTrainModel/encoder.pth'
/mnt/workspace/wangding/Desktop/TransWorldNG/experiment/HighD/data/highway02/preTrainModel/encoder.pth
2023-07-03 06:50:31,096,96,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.234031572302973 ---------
2023-07-03 06:50:31,096,96,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 51%|█████     | 51/100 [3:59:08<3:51:26, 283.40s/it]2023-07-03 06:50:31,344,344,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 51 --------
2023-07-03 06:50:31,346,346,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 06:50:31,350,350,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 06:50:31,353,353,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 06:55:09,299,299,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9639664869755507 ---------
2023-07-03 06:55:09,299,299,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 52%|█████▏    | 52/100 [4:03:46<3:45:28, 281.85s/it]2023-07-03 06:55:09,592,592,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 52 --------
2023-07-03 06:55:09,593,593,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 06:55:09,597,597,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 06:55:09,601,601,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:00:04,107,107,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2935164841738613 ---------
2023-07-03 07:00:04,108,108,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 53%|█████▎    | 53/100 [4:08:41<3:43:48, 285.72s/it]2023-07-03 07:00:04,325,325,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 53 --------
2023-07-03 07:00:04,327,327,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:00:04,330,330,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:00:04,333,333,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:04:52,515,515,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1552364257248966 ---------
2023-07-03 07:04:52,516,516,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 54%|█████▍    | 54/100 [4:13:29<3:39:40, 286.52s/it]2023-07-03 07:04:52,725,725,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 54 --------
2023-07-03 07:04:52,727,727,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:04:52,731,731,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:04:52,734,734,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:09:24,022,22,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9209858233278447 ---------
2023-07-03 07:09:24,023,23,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 55%|█████▌    | 55/100 [4:18:01<3:31:35, 282.12s/it]2023-07-03 07:09:24,572,572,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 55 --------
2023-07-03 07:09:24,573,573,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:09:24,577,577,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:09:24,581,581,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:14:02,084,84,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1844282800501045 ---------
2023-07-03 07:14:02,085,85,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 56%|█████▌    | 56/100 [4:22:39<3:25:55, 280.81s/it]2023-07-03 07:14:02,338,338,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 56 --------
2023-07-03 07:14:02,343,343,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:14:02,346,346,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:14:02,350,350,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:18:50,804,804,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.24763666770675 ---------
2023-07-03 07:18:50,805,805,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 57%|█████▋    | 57/100 [4:27:28<3:22:56, 283.18s/it]2023-07-03 07:18:51,027,27,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 57 --------
2023-07-03 07:18:51,029,29,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:18:51,033,33,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:18:51,035,35,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:23:34,333,333,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2361316321502356 ---------
2023-07-03 07:23:34,334,334,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 58%|█████▊    | 58/100 [4:32:11<3:18:17, 283.28s/it]2023-07-03 07:23:34,549,549,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 58 --------
2023-07-03 07:23:34,550,550,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:23:34,554,554,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:23:34,558,558,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:28:23,822,822,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.265230079012161 ---------
2023-07-03 07:28:23,823,823,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 59%|█████▉    | 59/100 [4:37:01<3:14:52, 285.19s/it]2023-07-03 07:28:24,210,210,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 59 --------
2023-07-03 07:28:24,212,212,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:28:24,216,216,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:28:24,219,219,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:33:08,379,379,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2323143908923324 ---------
2023-07-03 07:33:08,380,380,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 60%|██████    | 60/100 [4:41:46<3:10:00, 285.01s/it]2023-07-03 07:33:08,781,781,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 60 --------
2023-07-03 07:33:08,783,783,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:33:08,787,787,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:33:08,790,790,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:37:41,301,301,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.895925229245966 ---------
2023-07-03 07:37:41,302,302,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 61%|██████    | 61/100 [4:46:18<3:02:52, 281.35s/it]2023-07-03 07:37:41,592,592,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 61 --------
2023-07-03 07:37:41,593,593,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:37:41,597,597,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:37:41,600,600,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:42:32,128,128,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.2504218642769214 ---------
2023-07-03 07:42:32,129,129,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 62%|██████▏   | 62/100 [4:51:09<2:59:59, 284.20s/it]2023-07-03 07:42:32,454,454,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 62 --------
2023-07-03 07:42:32,456,456,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:42:32,460,460,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:42:32,463,463,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:45:57,367,367,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== process HighD_highway02_50_4_4_pred_step_10  is running! ===========
2023-07-03 07:45:57,649,649,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
       height  width       x  ...      y  yAcceleration  yVelocity
0        2.50  19.81  413.22  ...  25.65           0.04       0.16
1        2.50  12.13  363.67  ...  25.21           0.02       0.09
2        2.50  12.13  364.56  ...  25.21           0.02       0.09
3        2.50  12.13  365.46  ...  25.22           0.02       0.09
4        2.50  12.13  366.37  ...  25.22           0.02       0.09
...       ...    ...     ...  ...    ...            ...        ...
22197    1.92   5.00    6.33  ...  21.73          -0.00      -0.18
22198    1.92   5.00    7.66  ...  21.72          -0.00      -0.18
22502    1.82   4.04  406.76  ...   9.27          -0.00       0.09
22503    1.82   4.04  405.81  ...   9.27          -0.01       0.08
22504    1.82   4.04  404.82  ...   9.28          -0.01       0.08

[19131 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-07-03 07:46:04,671,671,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 07:46:26,021,21,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= 10_50_1 =========
2023-07-03 07:46:26,963,963,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 286, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 217, in run
    encoder.load_state_dict(torch.load(encoder_path))
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1604, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for HGT:
	size mismatch for gnns.0.residual_w: copying a param with shape torch.Size([100, 400]) from checkpoint, the shape in current model is torch.Size([50, 200]).
	size mismatch for gnns.0.linear_k.W: copying a param with shape torch.Size([2, 100, 400]) from checkpoint, the shape in current model is torch.Size([2, 50, 200]).
	size mismatch for gnns.0.linear_q.W: copying a param with shape torch.Size([2, 100, 400]) from checkpoint, the shape in current model is torch.Size([2, 50, 200]).
	size mismatch for gnns.0.linear_v.W: copying a param with shape torch.Size([2, 100, 400]) from checkpoint, the shape in current model is torch.Size([2, 50, 200]).
	size mismatch for gnns.0.linear_a.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.0.relation_att.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_att.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_att.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_att.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_msg.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_msg.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_msg.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_msg.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.norm.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.0.norm.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.1.linear_k.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.1.linear_q.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.1.linear_v.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.1.linear_a.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.1.relation_att.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_att.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_att.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_att.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_msg.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_msg.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_msg.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_msg.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.norm.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.1.norm.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.2.linear_k.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.2.linear_q.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.2.linear_v.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.2.linear_a.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.2.relation_att.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_att.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_att.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_att.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_msg.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_msg.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_msg.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_msg.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.norm.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.2.norm.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.3.linear_k.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.3.linear_q.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.3.linear_v.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.3.linear_a.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.3.relation_att.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_att.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_att.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_att.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_msg.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_msg.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_msg.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_msg.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.norm.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.3.norm.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for linears.0.weight: copying a param with shape torch.Size([400, 400]) from checkpoint, the shape in current model is torch.Size([200, 200]).
	size mismatch for linears.0.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for linears.1.weight: copying a param with shape torch.Size([400, 400]) from checkpoint, the shape in current model is torch.Size([200, 200]).
	size mismatch for linears.1.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for linears.2.weight: copying a param with shape torch.Size([400, 400]) from checkpoint, the shape in current model is torch.Size([200, 200]).
	size mismatch for linears.2.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for linears.3.weight: copying a param with shape torch.Size([400, 400]) from checkpoint, the shape in current model is torch.Size([200, 200]).
	size mismatch for linears.3.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.0.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.0.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.0.running_mean: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.0.running_var: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.1.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.1.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.1.running_mean: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.1.running_var: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.2.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.2.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.2.running_mean: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.2.running_var: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.3.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.3.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.3.running_mean: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.3.running_var: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for hetero_input_projector.linears.veh.weight: copying a param with shape torch.Size([50, 9]) from checkpoint, the shape in current model is torch.Size([25, 9]).
	size mismatch for hetero_input_projector.linears.veh.bias: copying a param with shape torch.Size([50]) from checkpoint, the shape in current model is torch.Size([25]).
	size mismatch for hetero_input_projector.linears.lane.weight: copying a param with shape torch.Size([50, 5]) from checkpoint, the shape in current model is torch.Size([25, 5]).
	size mismatch for hetero_input_projector.linears.lane.bias: copying a param with shape torch.Size([50]) from checkpoint, the shape in current model is torch.Size([25]).
	size mismatch for hetero_input_projector.projector.weight: copying a param with shape torch.Size([100, 50]) from checkpoint, the shape in current model is torch.Size([50, 25]).
	size mismatch for hetero_input_projector.projector.bias: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([50]).
/mnt/workspace/wangding/Desktop/TransWorldNG/experiment/HighD/data/highway02/preTrainModel/encoder.pth
2023-07-03 07:47:04,824,824,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 1.9244021312756971 ---------
2023-07-03 07:47:04,825,825,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 63%|██████▎   | 63/100 [4:55:42<2:53:07, 280.73s/it]2023-07-03 07:47:05,093,93,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 63 --------
2023-07-03 07:47:05,095,95,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:47:05,098,98,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:47:05,100,100,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:51:46,085,85,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1968125385147603 ---------
2023-07-03 07:51:46,085,85,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 64%|██████▍   | 64/100 [5:00:23<2:48:32, 280.89s/it]2023-07-03 07:51:46,359,359,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 64 --------
2023-07-03 07:51:46,361,361,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:51:46,365,365,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:51:46,368,368,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:56:22,656,656,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.295681957494129 ---------
2023-07-03 07:56:22,657,657,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 65%|██████▌   | 65/100 [5:05:00<2:43:05, 279.59s/it]2023-07-03 07:56:22,913,913,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 65 --------
2023-07-03 07:56:22,916,916,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:56:22,920,920,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:56:22,928,928,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 07:56:31,477,477,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== process HighD_highway02_50_4_4_pred_step_10  is running! ===========
2023-07-03 07:56:31,949,949,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
       height  width       x  ...      y  yAcceleration  yVelocity
0        2.50  19.81  413.22  ...  25.65           0.04       0.16
1        2.50  12.13  363.67  ...  25.21           0.02       0.09
2        2.50  12.13  364.56  ...  25.21           0.02       0.09
3        2.50  12.13  365.46  ...  25.22           0.02       0.09
4        2.50  12.13  366.37  ...  25.22           0.02       0.09
...       ...    ...     ...  ...    ...            ...        ...
22197    1.92   5.00    6.33  ...  21.73          -0.00      -0.18
22198    1.92   5.00    7.66  ...  21.72          -0.00      -0.18
22502    1.82   4.04  406.76  ...   9.27          -0.00       0.09
22503    1.82   4.04  405.81  ...   9.27          -0.01       0.08
22504    1.82   4.04  404.82  ...   9.28          -0.01       0.08

[19131 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-07-03 07:56:45,993,993,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 07:57:09,782,782,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= 10_50_1 =========
2023-07-03 07:57:10,717,717,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========

  0%|          | 0/10 [00:00<?, ?it/s]2023-07-03 07:57:10,721,721,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-07-03 07:57:10,723,723,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 07:57:10,728,728,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 07:57:10,729,729,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= start training =======
ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).
 
  0%|          | 0/10 [00:52<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 98960) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 286, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 226, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 42, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader):  # 这里for的是时间戳
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1325, in _get_data
    success, data = self._try_get_data()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1176, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 98960) exited unexpectedly
2023-07-03 08:01:06,278,278,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.081194281578064 ---------
2023-07-03 08:01:06,278,278,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 66%|██████▌   | 66/100 [5:09:43<2:39:07, 280.80s/it]2023-07-03 08:01:06,530,530,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 66 --------
2023-07-03 08:01:06,532,532,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 08:01:06,536,536,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 08:01:06,539,539,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 08:05:41,815,815,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.04029336029833 ---------
2023-07-03 08:05:41,816,816,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 67%|██████▋   | 67/100 [5:14:19<2:33:35, 279.25s/it]2023-07-03 08:05:42,166,166,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 67 --------
2023-07-03 08:05:42,169,169,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 08:05:42,173,173,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 08:05:42,178,178,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 08:10:24,371,371,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.1926765780557287 ---------
2023-07-03 08:10:24,371,371,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 68%|██████▊   | 68/100 [5:19:01<2:29:27, 280.24s/it]2023-07-03 08:10:24,726,726,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 68 --------
2023-07-03 08:10:24,727,727,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 08:10:24,728,728,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 08:10:24,731,731,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 08:14:04,190,190,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== process HighD_highway02_50_4_4_pred_step_10  is running! ===========
2023-07-03 08:14:04,471,471,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
       height  width       x  ...      y  yAcceleration  yVelocity
0        2.50  19.81  413.22  ...  25.65           0.04       0.16
1        2.50  12.13  363.67  ...  25.21           0.02       0.09
2        2.50  12.13  364.56  ...  25.21           0.02       0.09
3        2.50  12.13  365.46  ...  25.22           0.02       0.09
4        2.50  12.13  366.37  ...  25.22           0.02       0.09
...       ...    ...     ...  ...    ...            ...        ...
22197    1.92   5.00    6.33  ...  21.73          -0.00      -0.18
22198    1.92   5.00    7.66  ...  21.72          -0.00      -0.18
22502    1.82   4.04  406.76  ...   9.27          -0.00       0.09
22503    1.82   4.04  405.81  ...   9.27          -0.01       0.08
22504    1.82   4.04  404.82  ...   9.28          -0.01       0.08

[19131 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-07-03 08:14:11,474,474,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 08:14:32,855,855,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= 10_50_1 =========
2023-07-03 08:14:33,720,720,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========

  0%|          | 0/10 [00:00<?, ?it/s]2023-07-03 08:14:33,723,723,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-07-03 08:14:33,725,725,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 08:14:33,728,728,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 08:14:33,730,730,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= start training =======
2023-07-03 08:15:02,514,514,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::------------ loss is 2.195714199661531 ---------
2023-07-03 08:15:02,515,515,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finished training ==========

 69%|██████▉   | 69/100 [5:23:40<2:24:27, 279.61s/it]2023-07-03 08:15:02,860,860,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 69 --------
2023-07-03 08:15:02,862,862,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 08:15:02,862,862,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 08:15:02,864,864,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 244, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/multiprocessing/reductions.py", line 358, in reduce_storage
    fd, size = storage._share_fd_cpu_()
RuntimeError: unable to write to file </torch_101305_2490091294_26>: No space left on device (28)
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 244, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/multiprocessing/reductions.py", line 358, in reduce_storage
    fd, size = storage._share_fd_cpu_()
RuntimeError: unable to write to file </torch_101305_3308177264_27>: No space left on device (28)
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 244, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/multiprocessing/reductions.py", line 358, in reduce_storage
    fd, size = storage._share_fd_cpu_()
RuntimeError: unable to write to file </torch_101152_1524102890_2400>: No space left on device (28)
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 244, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/multiprocessing/reductions.py", line 358, in reduce_storage
    fd, size = storage._share_fd_cpu_()
RuntimeError: unable to write to file </torch_101152_125078735_2401>: No space left on device (28)
2023-07-03 08:22:17,286,286,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== process hangzhou_test500_50_4_4_pred_step_10  is running! ===========
2023-07-03 08:22:24,392,392,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
2023-07-03 08:23:07,886,886,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 08:24:19,762,762,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= 10_4_1 =========
2023-07-03 08:24:20,673,673,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
2023-07-03 08:24:20,698,698,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== Finish load preTrain model ==========
  0%|          | 0/10 [00:00<?, ?it/s]2023-07-03 08:24:20,699,699,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-07-03 08:24:20,702,702,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 08:24:20,705,705,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 08:24:20,710,710,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
  0%|          | 0/10 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_finetune.py", line 280, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_finetune.py", line 228, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_finetune.py", line 40, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader): 
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1050, in __init__
    self._worker_result_queue = multiprocessing_context.Queue()  # type: ignore[var-annotated]
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 103, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 43, in __init__
    self._rlock = ctx.Lock()
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 68, in Lock
    return Lock(ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 162, in __init__
    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 57, in __init__
    sl = self._semlock = _multiprocessing.SemLock(
OSError: [Errno 28] No space left on device
2023-07-03 08:34:16,177,177,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== process hangzhou_test500_50_4_4_pred_step_10  is running! ===========
2023-07-03 08:34:23,278,278,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
2023-07-03 08:35:06,784,784,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 08:36:18,251,251,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= 10_20_1 =========
2023-07-03 08:36:19,258,258,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
2023-07-03 08:36:19,282,282,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== Finish load preTrain model ==========
  0%|          | 0/10 [00:00<?, ?it/s]2023-07-03 08:36:19,284,284,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-07-03 08:36:19,287,287,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 08:36:19,289,289,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 08:36:19,295,295,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
  0%|          | 0/10 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_finetune.py", line 280, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_finetune.py", line 228, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_finetune.py", line 40, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader): 
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1050, in __init__
    self._worker_result_queue = multiprocessing_context.Queue()  # type: ignore[var-annotated]
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 103, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 43, in __init__
    self._rlock = ctx.Lock()
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 68, in Lock
    return Lock(ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 162, in __init__
    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 57, in __init__
    sl = self._semlock = _multiprocessing.SemLock(
OSError: [Errno 28] No space left on device
2023-07-03 08:38:43,922,922,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== process HighD_highway02_50_4_4_pred_step_10  is running! ===========
2023-07-03 08:38:44,200,200,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
       height  width       x  ...      y  yAcceleration  yVelocity
0        2.50  19.81  413.22  ...  25.65           0.04       0.16
1        2.50  12.13  363.67  ...  25.21           0.02       0.09
2        2.50  12.13  364.56  ...  25.21           0.02       0.09
3        2.50  12.13  365.46  ...  25.22           0.02       0.09
4        2.50  12.13  366.37  ...  25.22           0.02       0.09
...       ...    ...     ...  ...    ...            ...        ...
22197    1.92   5.00    6.33  ...  21.73          -0.00      -0.18
22198    1.92   5.00    7.66  ...  21.72          -0.00      -0.18
22502    1.82   4.04  406.76  ...   9.27          -0.00       0.09
22503    1.82   4.04  405.81  ...   9.27          -0.01       0.08
22504    1.82   4.04  404.82  ...   9.28          -0.01       0.08

[19131 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-07-03 08:38:51,214,214,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 08:39:12,654,654,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= 10_500_1 =========
2023-07-03 08:39:13,501,501,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
  0%|          | 0/10 [00:00<?, ?it/s]2023-07-03 08:39:13,505,505,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-07-03 08:39:13,507,507,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 08:39:13,516,516,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 08:39:13,519,519,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= start training =======
  0%|          | 0/10 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 286, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 226, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 42, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader):  # 这里for的是时间戳
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1050, in __init__
    self._worker_result_queue = multiprocessing_context.Queue()  # type: ignore[var-annotated]
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 103, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 43, in __init__
    self._rlock = ctx.Lock()
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 68, in Lock
    return Lock(ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 162, in __init__
    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 57, in __init__
    sl = self._semlock = _multiprocessing.SemLock(
OSError: [Errno 28] No space left on device
Traceback (most recent call last):
  File "/home/pai/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/pai/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 9, in <module>
    from game.model import HGT, RuleBasedGenerator, GraphStateLoss
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/game/__init__.py", line 1, in <module>
    from .core.init import init
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/game/core/__init__.py", line 1, in <module>
    from game.core.controller import Controller
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/game/core/controller.py", line 4, in <module>
    from functools import singledispatchmethod
ImportError: cannot import name 'singledispatchmethod'
Traceback (most recent call last):
  File "/home/pai/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/pai/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 9, in <module>
    from game.model import HGT, RuleBasedGenerator, GraphStateLoss
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/game/__init__.py", line 1, in <module>
    from .core.init import init
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/game/core/__init__.py", line 1, in <module>
    from game.core.controller import Controller
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/game/core/controller.py", line 4, in <module>
    from functools import singledispatchmethod
ImportError: cannot import name 'singledispatchmethod'
Traceback (most recent call last):
  File "/home/pai/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/pai/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 9, in <module>
    from game.model import HGT, RuleBasedGenerator, GraphStateLoss
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/game/__init__.py", line 1, in <module>
    from .core.init import init
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/game/core/__init__.py", line 1, in <module>
    from game.core.controller import Controller
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/game/core/controller.py", line 4, in <module>
    from functools import singledispatchmethod
ImportError: cannot import name 'singledispatchmethod'
2023-07-03 08:57:38,236,236,INFO,scenario_HighDtest_data_highway02_dim_100_n_heads_4_n_layer_4::========== process HighD_highway02_100_4_4_pred_step_10  is running! ===========
2023-07-03 08:57:38,525,525,INFO,scenario_HighDtest_data_highway02_dim_100_n_heads_4_n_layer_4::========== finish load route and depart ========
       height  width       x  ...      y  yAcceleration  yVelocity
0        2.50  19.81  413.22  ...  25.65           0.04       0.16
1        2.50  12.13  363.67  ...  25.21           0.02       0.09
2        2.50  12.13  364.56  ...  25.21           0.02       0.09
3        2.50  12.13  365.46  ...  25.22           0.02       0.09
4        2.50  12.13  366.37  ...  25.22           0.02       0.09
...       ...    ...     ...  ...    ...            ...        ...
22197    1.92   5.00    6.33  ...  21.73          -0.00      -0.18
22198    1.92   5.00    7.66  ...  21.72          -0.00      -0.18
22502    1.82   4.04  406.76  ...   9.27          -0.00       0.09
22503    1.82   4.04  405.81  ...   9.27          -0.01       0.08
22504    1.82   4.04  404.82  ...   9.28          -0.01       0.08

[19131 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-07-03 08:57:45,549,549,INFO,scenario_HighDtest_data_highway02_dim_100_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 08:58:07,029,29,INFO,scenario_HighDtest_data_highway02_dim_100_n_heads_4_n_layer_4::========= 10_500_1 =========
2023-07-03 08:58:08,137,137,INFO,scenario_HighDtest_data_highway02_dim_100_n_heads_4_n_layer_4::========== finish generate generator rule ==========
  0%|          | 0/10 [00:00<?, ?it/s]2023-07-03 08:58:08,139,139,INFO,scenario_HighDtest_data_highway02_dim_100_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-07-03 08:58:08,141,141,INFO,scenario_HighDtest_data_highway02_dim_100_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 08:58:08,145,145,INFO,scenario_HighDtest_data_highway02_dim_100_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 08:58:08,147,147,INFO,scenario_HighDtest_data_highway02_dim_100_n_heads_4_n_layer_4::========= start training =======
  0%|          | 0/10 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 286, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 226, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 42, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader):  # 这里for的是时间戳
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1050, in __init__
    self._worker_result_queue = multiprocessing_context.Queue()  # type: ignore[var-annotated]
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 103, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 43, in __init__
    self._rlock = ctx.Lock()
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 68, in Lock
    return Lock(ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 162, in __init__
    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 57, in __init__
    sl = self._semlock = _multiprocessing.SemLock(
OSError: [Errno 28] No space left on device
2023-07-03 09:20:46,493,493,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== process HighD_highway02_50_4_4_pred_step_10  is running! ===========
2023-07-03 09:20:46,785,785,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
       height  width       x  ...      y  yAcceleration  yVelocity
0        2.50  19.81  413.22  ...  25.65           0.04       0.16
1        2.50  12.13  363.67  ...  25.21           0.02       0.09
2        2.50  12.13  364.56  ...  25.21           0.02       0.09
3        2.50  12.13  365.46  ...  25.22           0.02       0.09
4        2.50  12.13  366.37  ...  25.22           0.02       0.09
...       ...    ...     ...  ...    ...            ...        ...
22197    1.92   5.00    6.33  ...  21.73          -0.00      -0.18
22198    1.92   5.00    7.66  ...  21.72          -0.00      -0.18
22502    1.82   4.04  406.76  ...   9.27          -0.00       0.09
22503    1.82   4.04  405.81  ...   9.27          -0.01       0.08
22504    1.82   4.04  404.82  ...   9.28          -0.01       0.08

[19131 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-07-03 09:20:53,875,875,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 09:21:15,262,262,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= 10_500_1 =========
2023-07-03 09:21:16,236,236,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 289, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 220, in run
    encoder.load_state_dict(torch.load(encoder_path))
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1604, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for HGT:
	size mismatch for gnns.0.residual_w: copying a param with shape torch.Size([100, 400]) from checkpoint, the shape in current model is torch.Size([50, 200]).
	size mismatch for gnns.0.linear_k.W: copying a param with shape torch.Size([2, 100, 400]) from checkpoint, the shape in current model is torch.Size([2, 50, 200]).
	size mismatch for gnns.0.linear_q.W: copying a param with shape torch.Size([2, 100, 400]) from checkpoint, the shape in current model is torch.Size([2, 50, 200]).
	size mismatch for gnns.0.linear_v.W: copying a param with shape torch.Size([2, 100, 400]) from checkpoint, the shape in current model is torch.Size([2, 50, 200]).
	size mismatch for gnns.0.linear_a.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.0.relation_att.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_att.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_att.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_att.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_msg.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_msg.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_msg.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.relation_msg.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.0.norm.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.0.norm.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.1.linear_k.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.1.linear_q.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.1.linear_v.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.1.linear_a.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.1.relation_att.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_att.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_att.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_att.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_msg.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_msg.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_msg.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.relation_msg.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.1.norm.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.1.norm.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.2.linear_k.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.2.linear_q.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.2.linear_v.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.2.linear_a.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.2.relation_att.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_att.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_att.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_att.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_msg.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_msg.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_msg.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.relation_msg.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.2.norm.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.2.norm.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.3.linear_k.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.3.linear_q.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.3.linear_v.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.3.linear_a.W: copying a param with shape torch.Size([2, 400, 400]) from checkpoint, the shape in current model is torch.Size([2, 200, 200]).
	size mismatch for gnns.3.relation_att.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_att.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_att.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_att.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_msg.0.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_msg.1.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_msg.2.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.relation_msg.3.W: copying a param with shape torch.Size([2, 100, 100]) from checkpoint, the shape in current model is torch.Size([2, 50, 50]).
	size mismatch for gnns.3.norm.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for gnns.3.norm.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for linears.0.weight: copying a param with shape torch.Size([400, 400]) from checkpoint, the shape in current model is torch.Size([200, 200]).
	size mismatch for linears.0.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for linears.1.weight: copying a param with shape torch.Size([400, 400]) from checkpoint, the shape in current model is torch.Size([200, 200]).
	size mismatch for linears.1.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for linears.2.weight: copying a param with shape torch.Size([400, 400]) from checkpoint, the shape in current model is torch.Size([200, 200]).
	size mismatch for linears.2.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for linears.3.weight: copying a param with shape torch.Size([400, 400]) from checkpoint, the shape in current model is torch.Size([200, 200]).
	size mismatch for linears.3.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.0.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.0.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.0.running_mean: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.0.running_var: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.1.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.1.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.1.running_mean: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.1.running_var: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.2.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.2.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.2.running_mean: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.2.running_var: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.3.weight: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.3.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.3.running_mean: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for bns.3.running_var: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([200]).
	size mismatch for hetero_input_projector.linears.veh.weight: copying a param with shape torch.Size([50, 9]) from checkpoint, the shape in current model is torch.Size([25, 9]).
	size mismatch for hetero_input_projector.linears.veh.bias: copying a param with shape torch.Size([50]) from checkpoint, the shape in current model is torch.Size([25]).
	size mismatch for hetero_input_projector.linears.lane.weight: copying a param with shape torch.Size([50, 5]) from checkpoint, the shape in current model is torch.Size([25, 5]).
	size mismatch for hetero_input_projector.linears.lane.bias: copying a param with shape torch.Size([50]) from checkpoint, the shape in current model is torch.Size([25]).
	size mismatch for hetero_input_projector.projector.weight: copying a param with shape torch.Size([100, 50]) from checkpoint, the shape in current model is torch.Size([50, 25]).
	size mismatch for hetero_input_projector.projector.bias: copying a param with shape torch.Size([100]) from checkpoint, the shape in current model is torch.Size([50]).
/mnt/data/saclab/wangding/Desktop/TransWorldNG/experiment/HighD/data/highway02/preTrainModel/encoder.pth
2023-07-03 09:22:40,379,379,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== process HighD_highway02_50_4_4_pred_step_10  is running! ===========
2023-07-03 09:22:40,670,670,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
       height  width       x  ...      y  yAcceleration  yVelocity
0        2.50  19.81  413.22  ...  25.65           0.04       0.16
1        2.50  12.13  363.67  ...  25.21           0.02       0.09
2        2.50  12.13  364.56  ...  25.21           0.02       0.09
3        2.50  12.13  365.46  ...  25.22           0.02       0.09
4        2.50  12.13  366.37  ...  25.22           0.02       0.09
...       ...    ...     ...  ...    ...            ...        ...
22197    1.92   5.00    6.33  ...  21.73          -0.00      -0.18
22198    1.92   5.00    7.66  ...  21.72          -0.00      -0.18
22502    1.82   4.04  406.76  ...   9.27          -0.00       0.09
22503    1.82   4.04  405.81  ...   9.27          -0.01       0.08
22504    1.82   4.04  404.82  ...   9.28          -0.01       0.08

[19131 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-07-03 09:22:47,707,707,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 09:23:09,186,186,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= 10_500_1 =========
2023-07-03 09:23:10,176,176,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
  0%|          | 0/10 [00:00<?, ?it/s]2023-07-03 09:23:10,178,178,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-07-03 09:23:10,180,180,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 09:23:10,185,185,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 09:23:10,188,188,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= start training =======
  0%|          | 0/10 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 289, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 229, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 42, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader):  # 这里for的是时间戳
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1050, in __init__
    self._worker_result_queue = multiprocessing_context.Queue()  # type: ignore[var-annotated]
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 103, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 43, in __init__
    self._rlock = ctx.Lock()
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 68, in Lock
    return Lock(ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 162, in __init__
    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 57, in __init__
    sl = self._semlock = _multiprocessing.SemLock(
OSError: [Errno 28] No space left on device
2023-07-03 09:45:23,820,820,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== process HighD_highway02_50_4_4_pred_step_10  is running! ===========
2023-07-03 09:45:24,108,108,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
       height  width       x  ...      y  yAcceleration  yVelocity
0        2.50  19.81  413.22  ...  25.65           0.04       0.16
1        2.50  12.13  363.67  ...  25.21           0.02       0.09
2        2.50  12.13  364.56  ...  25.21           0.02       0.09
3        2.50  12.13  365.46  ...  25.22           0.02       0.09
4        2.50  12.13  366.37  ...  25.22           0.02       0.09
...       ...    ...     ...  ...    ...            ...        ...
15255    2.22   4.45  322.61  ...   9.45           0.03       0.03
15256    2.22   4.45  321.40  ...   9.45           0.03       0.03
15257    2.22   4.45  320.18  ...   9.45           0.03       0.03
15258    2.22   4.45  318.96  ...   9.45           0.03       0.03
15259    2.22   4.45  317.74  ...   9.45           0.03       0.03

[13436 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-07-03 09:45:29,402,402,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 09:45:44,510,510,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= 10_500_1 =========
2023-07-03 09:45:45,577,577,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
  0%|          | 0/10 [00:00<?, ?it/s]2023-07-03 09:45:45,580,580,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-07-03 09:45:45,582,582,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 09:45:45,588,588,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 09:45:45,588,588,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= start training =======
  0%|          | 0/10 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 290, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 230, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 42, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader):  # 这里for的是时间戳
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1050, in __init__
    self._worker_result_queue = multiprocessing_context.Queue()  # type: ignore[var-annotated]
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 103, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 43, in __init__
    self._rlock = ctx.Lock()
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 68, in Lock
    return Lock(ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 162, in __init__
    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 57, in __init__
    sl = self._semlock = _multiprocessing.SemLock(
OSError: [Errno 28] No space left on device
2023-07-03 09:54:06,838,838,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== process hangzhou_test500_50_4_4_pred_step_10  is running! ===========
2023-07-03 09:54:14,125,125,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
2023-07-03 09:54:58,051,51,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
2023-07-03 09:56:10,041,41,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= 10_20_1 =========
2023-07-03 09:56:11,135,135,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
2023-07-03 09:56:11,185,185,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== Finish load preTrain model ==========
  0%|          | 0/10 [00:00<?, ?it/s]2023-07-03 09:56:11,187,187,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
2023-07-03 09:56:11,189,189,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
2023-07-03 09:56:11,193,193,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
2023-07-03 09:56:11,196,196,INFO,scenario_hangzhoutest_data_test500_dim_50_n_heads_4_n_layer_4::========= start training =======
  0%|          | 0/10 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_finetune.py", line 280, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_finetune.py", line 228, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_finetune.py", line 40, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader): 
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1050, in __init__
    self._worker_result_queue = multiprocessing_context.Queue()  # type: ignore[var-annotated]
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 103, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 43, in __init__
    self._rlock = ctx.Lock()
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 68, in Lock
    return Lock(ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 162, in __init__
    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 57, in __init__
    sl = self._semlock = _multiprocessing.SemLock(
OSError: [Errno 28] No space left on device
2023-07-03 09:56:27,680,680,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== process HighD_highway02_50_4_4_pred_step_10  is running! ===========
--- Logging error ---
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1087, in emit
    self.flush()
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 95] Operation not supported
Call stack:
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 290, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 157, in run
    logger.info(f"========== finish load route and depart ========")
Message: '========== finish load route and depart ========'
Arguments: ()
2023-07-03 09:56:27,969,969,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish load route and depart ========
--- Logging error ---
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1087, in emit
    self.flush()
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 95] Operation not supported
Call stack:
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 290, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 162, in run
    logger.info(f"========= finish load graph =========")
Message: '========= finish load graph ========='
Arguments: ()
       height  width       x  ...      y  yAcceleration  yVelocity
0        2.50  19.81  413.22  ...  25.65           0.04       0.16
1        2.50  12.13  363.67  ...  25.21           0.02       0.09
2        2.50  12.13  364.56  ...  25.21           0.02       0.09
3        2.50  12.13  365.46  ...  25.22           0.02       0.09
4        2.50  12.13  366.37  ...  25.22           0.02       0.09
...       ...    ...     ...  ...    ...            ...        ...
15255    2.22   4.45  322.61  ...   9.45           0.03       0.03
15256    2.22   4.45  321.40  ...   9.45           0.03       0.03
15257    2.22   4.45  320.18  ...   9.45           0.03       0.03
15258    2.22   4.45  318.96  ...   9.45           0.03       0.03
15259    2.22   4.45  317.74  ...   9.45           0.03       0.03

[13436 rows x 8 columns]
feat_veh height
feat_veh width
feat_veh x
feat_veh xAcceleration
feat_veh xVelocity
feat_veh y
feat_veh yAcceleration
feat_veh yVelocity
feat_lane speed_avg
feat_lane width
feat_lane x
feat_lane y
2023-07-03 09:56:33,342,342,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= finish load graph =========
--- Logging error ---
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1087, in emit
    self.flush()
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 95] Operation not supported
Call stack:
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 290, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 176, in run
    logger.info(f"========= {n_epochs}_{batch_size}_{num_workers} =========")
Message: '========= 10_500_1 ========='
Arguments: ()
2023-07-03 09:56:48,453,453,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= 10_500_1 =========
--- Logging error ---
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1087, in emit
    self.flush()
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 95] Operation not supported
Call stack:
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 290, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 204, in run
    logger.info("========== finish generate generator rule ==========")
Message: '========== finish generate generator rule =========='
Arguments: ()
2023-07-03 09:56:49,419,419,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate generator rule ==========
  0%|          | 0/10 [00:00<?, ?it/s]--- Logging error ---
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1087, in emit
    self.flush()
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 95] Operation not supported
Call stack:
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 290, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 229, in run
    logger.info(f"--------- current ep is {ep} --------")
Message: '--------- current ep is 0 --------'
Arguments: ()
2023-07-03 09:56:49,442,442,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::--------- current ep is 0 --------
--- Logging error ---
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1087, in emit
    self.flush()
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 95] Operation not supported
Call stack:
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 290, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 230, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 35, in train
    logger.info("========= start generate dataset =======")
Message: '========= start generate dataset ======='
Arguments: ()
2023-07-03 09:56:49,459,459,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= start generate dataset =======
--- Logging error ---
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1087, in emit
    self.flush()
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 95] Operation not supported
Call stack:
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 290, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 230, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 38, in train
    logger.info("========== finish generate dataset =======")
Message: '========== finish generate dataset ======='
Arguments: ()
2023-07-03 09:56:49,484,484,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========== finish generate dataset =======
--- Logging error ---
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1087, in emit
    self.flush()
  File "/home/pai/envs/tsim_env/lib/python3.9/logging/__init__.py", line 1067, in flush
    self.stream.flush()
OSError: [Errno 95] Operation not supported
Call stack:
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 290, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 230, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 40, in train
    logger.info("========= start training =======")
Message: '========= start training ======='
Arguments: ()
2023-07-03 09:56:49,506,506,INFO,scenario_HighDtest_data_highway02_dim_50_n_heads_4_n_layer_4::========= start training =======
  0%|          | 0/10 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/pai/envs/tsim_env/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 290, in <module>
    run(args.scenario,args.train_data, args.training_step, args.pred_step, args.hid_dim, args.n_head, args.n_layer, device, args.pretrain_model_path)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 230, in run
    loss_lst = train(timestamps, graph, batch_size, num_workers, encoder, generator, veh_route, loss_fcn, optimizer, logger, device)
  File "/mnt/workspace/wangding/Desktop/TransWorldNG/transworld/transworld_hd.py", line 42, in train
    for i, (cur_graphs, next_graphs) in enumerate(train_loader):  # 这里for的是时间戳
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 444, in __iter__
    return self._get_iterator()
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 390, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/pai/envs/tsim_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1050, in __init__
    self._worker_result_queue = multiprocessing_context.Queue()  # type: ignore[var-annotated]
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 103, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/queues.py", line 43, in __init__
    self._rlock = ctx.Lock()
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/context.py", line 68, in Lock
    return Lock(ctx=self.get_context())
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 162, in __init__
    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)
  File "/home/pai/envs/tsim_env/lib/python3.9/multiprocessing/synchronize.py", line 57, in __init__
    sl = self._semlock = _multiprocessing.SemLock(
OSError: [Errno 28] No space left on device
